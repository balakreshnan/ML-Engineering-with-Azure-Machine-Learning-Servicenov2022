{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b889dd",
   "metadata": {},
   "source": [
    "# Deploy Model to online endpoint\n",
    "\n",
    "- Models created with MLFlow do not require a scoring script nor an environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f720af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0b6\n"
     ]
    }
   ],
   "source": [
    "import azure.ai.ml\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "\n",
    "print(azure.ai.ml._version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c554194",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '5da07161-3770-4a4b-aa43-418cbbb627cf'\n",
    "resource_group = 'aml-workspace-rg'\n",
    "workspace = 'aml-workspace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0e4818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    # This will open a browser page for\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af1dd297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/.azureml/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f373dcb64f0>,\n",
      "         subscription_id=5da07161-3770-4a4b-aa43-418cbbb627cf,\n",
      "         resource_group_name=aml-workspace-rg,\n",
      "         workspace_name=aml-workspace)\n"
     ]
    }
   ],
   "source": [
    "#connect to the workspace\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential=credential)\n",
    "except Exception as ex:\n",
    "    # NOTE: Update following workspace information if not correctly configure before\n",
    "    client_config = {\n",
    "        \"subscription_id\": subscription_id,\n",
    "        \"resource_group\": resource_group,\n",
    "        \"workspace_name\": workspace,\n",
    "    }\n",
    "\n",
    "    if client_config[\"subscription_id\"].startswith(\"<\"):\n",
    "        print(\n",
    "            \"please update your <SUBSCRIPTION_ID> <RESOURCE_GROUP> <AML_WORKSPACE_NAME> in notebook cell\"\n",
    "        )\n",
    "        raise ex\n",
    "    else:  # write and reload from config file\n",
    "        import json, os\n",
    "\n",
    "        config_path = \"../.azureml/config.json\"\n",
    "        os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "        with open(config_path, \"w\") as fo:\n",
    "            fo.write(json.dumps(client_config))\n",
    "        ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b8f3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Online Endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "848535be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configure endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d5c0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"titanic online endpoint for mlflow model\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"oneline endpoint\": \"titanic\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe9ff5",
   "metadata": {},
   "source": [
    "## Create endpoint\n",
    "\n",
    "Using the MLClient created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f7d3bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-08272238724667.eastus.inference.ml.azure.com/score', 'swagger_uri': 'https://endpoint-08272238724667.eastus.inference.ml.azure.com/swagger.json', 'name': 'endpoint-08272238724667', 'description': 'titanic online endpoint for mlflow model', 'tags': {'oneline endpoint': 'titanic'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/aml-workspace-rg/providers/microsoft.machinelearningservices/workspaces/aml-workspace/onlineendpoints/endpoint-08272238724667', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oe:88449c92-2fa7-4734-8cc5-76e1776b55bb:753af4b4-759e-49c7-816e-572d8f5cb6e0?api-version=2022-02-01-preview'}, 'id': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/aml-workspace-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-workspace/onlineEndpoints/endpoint-08272238724667', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/Chapter6', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f373f7ec400>, 'auth_mode': 'key', 'location': 'eastus', 'identity': <azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedServiceIdentity object at 0x7f373f7ec8e0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085b1c0",
   "metadata": {},
   "source": [
    "## Create deployment\n",
    "A deployment is a set of resouces used for hosting the inferecing model using the *ManagedOnlineDeployment* class.  \n",
    "Using the *ManagedOnlineDeployment* class, a developer can configure the following components\n",
    "\n",
    "- name: name of the deployment\n",
    "- endpoint_name: name of the endpoint to create the deployment under\n",
    "- model: the model to use for the deployment\n",
    "- instance_type: the VM side to use for deployment\n",
    "- instance_count: the number of instances to use for the deployment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09639b73",
   "metadata": {},
   "source": [
    "# Retrieve Model from registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "328d33f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7685ed2a-881e-4e77-8c82-429623276f43\n",
      "coral_gas_1hz6njncjl\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "experiment = 'Chapter6'\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)\n",
    "\n",
    "df = mlflow.search_runs([experiment_id])\n",
    "\n",
    "\n",
    "run_id = df['run_id'].iloc[-1]\n",
    "print(run_id)\n",
    "print(type(run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5eb43c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coral_gas_1hz6njncjl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<FileInfo: file_size=-1, is_dir=True, path='model'>,\n",
       " <FileInfo: file_size=-1, is_dir=True, path='system_logs'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='test_confusion_matrix.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='test_precision_recall_curve.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='test_roc_curve.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='training_confusion_matrix.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='training_precision_recall_curve.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='training_roc_curve.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=True, path='user_logs'>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "print(run_id)\n",
    "mlflow.set_experiment(experiment_name='Chapter6')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.list_artifacts(run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fadb6de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "file_path = client.download_artifacts(\n",
    "    run_id, path=\"model\"\n",
    ")\n",
    "shutil.copytree(file_path, './model', dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4482e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=\"./model/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6640cf75",
   "metadata": {},
   "source": [
    "## Get Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ad675b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ml_client.environments.get(name = 'job_base_env', version = \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56157a43",
   "metadata": {},
   "source": [
    "## Creating Scoring Script\n",
    "\n",
    "score.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d12b5d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ManagedOnlineEndpoint folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "script_folder = 'ManagedOnlineEndpoint'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a593c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ManagedOnlineEndpoint/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/score.py\n",
    "\n",
    "import os \n",
    "import json\n",
    "import joblib\n",
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    dict= json.loads(raw_data)\n",
    "    df = json_normalize(dict['raw_data']) \n",
    "    y_pred = model.predict(df)\n",
    "    print(type(y_pred))\n",
    "    \n",
    "    result = {\"result\": y_pred.tolist()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12c8d3",
   "metadata": {},
   "source": [
    "## Configure the deployment\n",
    "\n",
    "- retrieve the experiment id for this run, and the run id to retrieve the model from the registered model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7af2fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=\"azureml:job_base_env:1\",\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./ManagedOnlineEndpoint\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_type=\"Standard_F4s_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a1cbd",
   "metadata": {},
   "source": [
    "## Create deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf1519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint endpoint-08272238724667 exists\n",
      "\u001b[32mUploading model.pkl\u001b[32m (< 1 MB): 100%|██████████| 2.61k/2.61k [00:00<00:00, 140kB/s]\n",
      "\u001b[39m\n",
      "\n",
      "Creating/updating online deployment blue "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............."
     ]
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(blue_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deade271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Endpoint details\n",
    "\n",
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(endpoint)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e375b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82fc717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "url = endpoint.scoring_uri\n",
    "api_key = endpoint.key  # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "import requests\n",
    "\n",
    "def MakePrediction(df):\n",
    "    endpoint_url = url\n",
    "    body = df.to_json(orient='records') \n",
    "    body = '{\"raw_data\": ' + body + '}'\n",
    "    print(body)\n",
    "    r = requests.post(endpoint_url, headers=headers, data=body)\n",
    "    return (r.json())\n",
    "\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name='Titanic-tabular-dataset')\n",
    "df = dataset.to_pandas_dataframe().head(5)\n",
    "dftest = df.drop(['Survived'], axis=1)\n",
    "\n",
    "results = MakePrediction(dftest)\n",
    "\n",
    "val = results['result']\n",
    "print('')\n",
    "print('predictions')\n",
    "print(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
