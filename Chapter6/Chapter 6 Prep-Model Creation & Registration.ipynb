{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6 Model Deployment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azure.ai.ml\n",
        "print(azure.ai.ml._version.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.1.0b6\n"
        }
      ],
      "execution_count": 44,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml.entities import Environment, BuildContext"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_id = '5da07161-3770-4a4b-aa43-418cbbb627cf'\n",
        "resource_group = 'aml-workspace-rg'\n",
        "workspace = 'aml-workspace'"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to your workspace\n",
        "\n",
        "Once you connect to your workspace, you will create a new cpu target which you will provide an environment to.\n",
        "\n",
        "- Configure your credential.  We are using `DefaultAzureCredential`.  It will request a token using multiple identities, stopping once a token is found"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    # This will open a browser page for\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to the workspace\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential)\n",
        "except Exception as ex:\n",
        "    # NOTE: Update following workspace information if not correctly configure before\n",
        "    client_config = {\n",
        "        \"subscription_id\": subscription_id,\n",
        "        \"resource_group\": resource_group,\n",
        "        \"workspace_name\": workspace,\n",
        "    }\n",
        "\n",
        "    if client_config[\"subscription_id\"].startswith(\"<\"):\n",
        "        print(\n",
        "            \"please update your <SUBSCRIPTION_ID> <RESOURCE_GROUP> <AML_WORKSPACE_NAME> in notebook cell\"\n",
        "        )\n",
        "        raise ex\n",
        "    else:  # write and reload from config file\n",
        "        import json, os\n",
        "\n",
        "        config_path = \"../.azureml/config.json\"\n",
        "        os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
        "        with open(config_path, \"w\") as fo:\n",
        "            fo.write(json.dumps(client_config))\n",
        "        ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
        "print(ml_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/.azureml/config.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f062601aeb0>,\n         subscription_id=5da07161-3770-4a4b-aa43-418cbbb627cf,\n         resource_group_name=aml-workspace-rg,\n         workspace_name=aml-workspace)\n"
        }
      ],
      "execution_count": 48,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup enviroment\n",
        "\n",
        "### Creating environment from docker image with a conda YAML\n",
        "\n",
        "Azure ML allows you to leverage curated environments, as well as to build your own environment from:\n",
        "\n",
        "    - existing docker image\n",
        "    - base docker image with a conda yml file to customize\n",
        "    - a docker build content\n",
        "    \n",
        "We will proceed with creating an environment from a docker build plus a conda yml file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "script_folder = os.path.join(os.getcwd(), \"conda-yamls\")\n",
        "print(script_folder)\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/Chapter6/conda-yamls\n"
        }
      ],
      "execution_count": 49,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create job environment in a yml file"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/job_env.yml\n",
        "name: job_env\n",
        "dependencies:\n",
        "  # The python interpreter version.\n",
        "  # Currently Azure ML only supports 3.5.2 and later.\n",
        "- python=3.8.5\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow\n",
        "  - azureml-mlflow==1.43.0.post1\n",
        "  - azure-ai-ml\n",
        "  - mltable"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/Chapter6/conda-yamls/job_env.yml\n"
        }
      ],
      "execution_count": 50,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the most current and up-to-date base image\n",
        "\n",
        "Default images are always changing.  \n",
        "Note the base image is defined in the property `image` below.  These images are defined at [https://hub.docker.com/_/microsoft-azureml](https://hub.docker.com/_/microsoft-azureml)\n",
        "\n",
        "The current image we have selected for this notebook is `mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04`, but based on image availability, that will change in the future.  In additon, note the python version specified in your conda environment file is `python=3.8.5`, as this will evolve over time as well.  Currently `MLTable` is not available in python 3.10, but as that changes, we encourage you to update python version as well."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "env_docker_conda = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        "    conda_file=\"conda-yamls/job_env.yml\",\n",
        "    name=\"job_base_env\",\n",
        "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env_docker_conda)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'job_base_env', 'description': 'Environment created from a Docker image plus Conda environment.', 'tags': {}, 'properties': {}, 'id': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/aml-workspace-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-workspace/environments/job_base_env/versions/2022-08-27-21-31-56-1184941', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/Chapter6', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f0625fe4310>, 'serialize': <msrest.serialization.Serializer object at 0x7f0636f2a8e0>, 'version': '2022-08-27-21-31-56-1184941', 'latest_version': None, 'conda_file': {'dependencies': ['python=3.8.5', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow', 'azureml-mlflow==1.43.0.post1', 'azure-ai-ml', 'mltable']}], 'name': 'job_env'}, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'build': None, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'upload_hash': None, 'translated_conda_file': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Compute "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# specify aml compute name.\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    ml_client.compute.get(cpu_compute_target)\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "    compute = AmlCompute(\n",
        "        name=cpu_compute_target, size=\"STANDARD_D2_V2\", min_instances=0, max_instances=4, idle_time_before_scale_down = 1800\n",
        "    )\n",
        "    ml_client.compute.begin_create_or_update(compute)"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating code to generate Basic Model\n",
        "\n",
        "We will first create a model using the job command"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "script_folder = os.path.join(os.getcwd(), \"src\")\n",
        "print(script_folder)\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/Chapter6/src\n"
        }
      ],
      "execution_count": 53,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create main.py file for running in your command"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./src/main.py\n",
        "import os\n",
        "import mlflow\n",
        "import argparse\n",
        "from mlflow.tracking import MlflowClient\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score,roc_curve\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "# define functions\n",
        "def main(args):\n",
        "    # enable auto logging\n",
        "    current_run = mlflow.start_run()\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    # read in data\n",
        "    df = pd.read_csv(args.titanic_csv)\n",
        "    model = model_train('Survived', df, args.randomstate)\n",
        "    \n",
        "\n",
        "def model_train(LABEL, df, randomstate):\n",
        "    print('df.columns = ')\n",
        "    print(df.columns)\n",
        "    y_raw           = df[LABEL]\n",
        "    columns_to_keep = ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
        "    X_raw           = df[columns_to_keep]\n",
        "    \n",
        "    X_raw['Embarked'] = X_raw['Embarked'].astype(object)\n",
        "    X_raw['Loc'] = X_raw['Loc'].astype(object)\n",
        "    X_raw['Loc'] = X_raw['Sex'].astype(object)\n",
        "    X_raw['Pclass'] = X_raw['Pclass'].astype(float)\n",
        "    X_raw['Age'] = X_raw['Age'].astype(float)\n",
        "    X_raw['Fare'] = X_raw['Fare'].astype(float)\n",
        "    X_raw['GroupSize'] = X_raw['GroupSize'].astype(float)\n",
        "    \n",
        "\n",
        "\n",
        "    print(X_raw.columns)\n",
        "     # Train test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=randomstate)\n",
        "    \n",
        "    #use Logistic Regression estimator from scikit learn\n",
        "    lg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
        "    preprocessor = buildpreprocessorpipeline(X_train)\n",
        "    \n",
        "    #estimator instance\n",
        "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                               ('regressor', lg)], verbose=True)\n",
        "\n",
        "    model = clf.fit(X_train, y_train)\n",
        "    \n",
        "    print('type of X_test = ' + str(type(X_test)))\n",
        "          \n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    print('*****X_test************')\n",
        "    print(X_test)\n",
        "    \n",
        "    metrics = mlflow.sklearn.eval_and_log_metrics(model, X_test, y_test, prefix=\"test_\")\n",
        "    \n",
        "    #get the active run.\n",
        "    run = mlflow.active_run()\n",
        "    print(\"Active run_id: {}\".format(run.info.run_id))\n",
        "    MlflowClient().log_metric(run.info.run_id, \"metric\", 0.22)\n",
        "\n",
        "    \n",
        "    return model\n",
        "\n",
        "    mlflow.end_run()\n",
        "\n",
        "\n",
        "def buildpreprocessorpipeline(X_raw):\n",
        "\n",
        "    categorical_features = X_raw.select_dtypes(include=['object', 'bool']).columns\n",
        "    numeric_features = X_raw.select_dtypes(include=['float','int64']).columns\n",
        "\n",
        "    #categorical_features = ['Sex', 'Embarked', 'Loc']\n",
        "    categorical_transformer = Pipeline(steps=[('onehotencoder', \n",
        "                                               OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore'))])\n",
        "\n",
        "\n",
        "    #numeric_features = ['Pclass', 'Age', 'Fare', 'GroupSize']    \n",
        "    numeric_transformer1 = Pipeline(steps=[('scaler1', SimpleImputer(missing_values=np.nan, strategy = 'mean'))])\n",
        "    \n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('numeric1', numeric_transformer1, numeric_features),\n",
        "            ('categorical', categorical_transformer, categorical_features)], remainder='drop')\n",
        "    \n",
        "    return preprocessor\n",
        "\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--titanic-csv\", type=str)\n",
        "    parser.add_argument(\"--randomstate\", type=int, default=42)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./src/main.py\n"
        }
      ],
      "execution_count": 54,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure Command\n",
        "\n",
        "- `display_name` display name for the job\n",
        "- `description`  the description of the experiment\n",
        "- `code` path where the code is located\n",
        "- `command` command to run\n",
        "- `inputs`  dictionary of name value pairs using `${{inputs.<input_name>}}`\n",
        "    \n",
        "    - To use files or folder - using the `Input` class\n",
        "        \n",
        "        - `type` defaults to a `uri_folder` but this can be set to `uri_file` or `uri_folder`\n",
        "        - `path` is the path to the file or folder.  These can be local or remote leveraging **https, http, wasb`\n",
        "        \n",
        "            - To use an Azure ML dataset, this would be an Input `Input(type='uri_folder', path='my_dataset:1')`\n",
        "            \n",
        "            - `mode` is how the data should be delivered to the compute which include `ro_mount`(default), `rw_mount` and `download`\n",
        "\n",
        "- `environment`: environment to be used by compute when running command\n",
        "- `compute`: can be `local`, or a specificed compute name\n",
        "- `distribution`: distribution to leverage for distributed training scenerios including:\n",
        "        \n",
        "    - `Pytorch`\n",
        "    - `TensorFlow`\n",
        "    - `MPI`\n",
        "            "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create the command\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "myjob = command(\n",
        "    code=\"./src\",  # local path where the code is stored\n",
        "    command=\"python main.py --titanic ${{inputs.titanic}} --randomstate ${{inputs.randomstate}}\",\n",
        "    inputs={\n",
        "        \"titanic\": Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"azureml:titanic_prepped:1\",\n",
        "        ),\n",
        "        \"randomstate\": 0,\n",
        "    },\n",
        "    environment=\"job_base_env@latest\",\n",
        "    compute=\"cpu-cluster\",\n",
        "    display_name=\"sklearn-titanic\",\n",
        "    # description,\n",
        "    # experiment_name\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "script_folder = os.path.join(os.getcwd(), \"job\")\n",
        "print(script_folder)\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/Chapter6/job\n"
        }
      ],
      "execution_count": 56,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Command with SDK"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# submit the command\n",
        "returned_job = ml_client.create_or_update(myjob)"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register the Model \n",
        "\n",
        "Using the Python SDK V2 - we can register the Model for use.  \n",
        "\n",
        "Parameters for model registration include:\n",
        "\n",
        "- `path` - A remote uri or local path pointing at the model\n",
        "- `name` - A string value\n",
        "- `description` - A description for the model\n",
        "- `type` - valid values include: \n",
        "    - \"custom_model\"\n",
        "    - \"mlflow_model\" \n",
        "    - \"triton_model\".  \n",
        "    \n",
        "* Instead of typing out the `type`, you can use the AssetTypes in the namespace azure.ai.ml.constants as we have done below\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "runid = returned_job.name\n",
        "print('runid:' + runid)\n",
        "experiment = returned_job.experiment_name\n",
        "print(\"experiment:\" + experiment)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "runid:coral_gas_1hz6njncjl\nexperiment:Chapter6\n"
        }
      ],
      "execution_count": 58,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import time\n",
        "\n",
        "exp = mlflow.get_experiment_by_name(experiment)\n",
        "last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
        "\n",
        "if last_run.info.run_id != runid:\n",
        "    print('run ids were not the same - waiting for run id to update')\n",
        "    time.sleep(5)\n",
        "    exp = mlflow.get_experiment_by_name(experiment)\n",
        "    last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
        "\n",
        "while last_run.info.status == 'SCHEDULED':\n",
        "  print('run is being scheduled')\n",
        "  time.sleep(5)\n",
        "  last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
        "\n",
        "while last_run.info.status == 'RUNNING':\n",
        "  print('job is being run')\n",
        "  time.sleep(10)\n",
        "  last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
        "\n",
        "print(\"run_id:{}\".format(last_run.info.run_id))\n",
        "print('----------')\n",
        "print(\"run_id:{}\".format(last_run.info.status))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "run_id:coral_gas_1hz6njncjl\n----------\nrun_id:FINISHED\n"
        }
      ],
      "execution_count": 60,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register the Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/Azure/azureml-examples/blob/march-sdk-preview/sdk/assets/model/model.ipynb\n",
        "from azure.ml._constants import ModelType"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'azure.ml'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#https://github.com/Azure/azureml-examples/blob/march-sdk-preview/sdk/assets/model/model.ipynb\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelType\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azure.ml'"
          ]
        }
      ],
      "execution_count": 64,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# run_model = Model(\n",
        "#     path=f\"runs:/{last_run.info.run_id}/model\",\n",
        "#     name=\"chapter6_titanic_model\",\n",
        "#     description=\"Model created from run.\",\n",
        "#     type=AssetTypes.MLFLOW_MODEL \n",
        "# )\n",
        "job_name = runid\n",
        "\n",
        "run_model = Model(\n",
        "    path=\"azureml://jobs/\" + last_run.info.run_id  + \"/outputs/artifacts/paths/model/\",\n",
        "    #Users could also use, \"azureml://jobs/XXXXXXXXXXXXXXXXXXXXXXXXX/outputs/artifacts/paths/model/\" as a shorthand to the same location\n",
        "    name=\"run-model-example\",\n",
        "    description=\"Model created from run.\",\n",
        "    type=AssetTypes.MLFLOW_MODEL\n",
        ")\n",
        "\n",
        "ml_client.models.create_or_update(run_model) "
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 73,
          "data": {
            "text/plain": "Model({'job_name': 'coral_gas_1hz6njncjl', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'run-model-example', 'description': 'Model created from run.', 'tags': {}, 'properties': {}, 'id': '/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/aml-workspace-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-workspace/models/run-model-example/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/Chapter6', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f0625405700>, 'serialize': <msrest.serialization.Serializer object at 0x7f062546fa60>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/aml-workspace-rg/workspaces/aml-workspace/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.coral_gas_1hz6njncjl/model', 'utc_time_created': None, 'flavors': {'python_function': {'env': 'conda.yaml', 'loader_module': 'mlflow.sklearn', 'model_path': 'model.pkl', 'python_version': '3.8.5'}, 'sklearn': {'code': '', 'pickled_model': 'model.pkl', 'serialization_format': 'cloudpickle', 'sklearn_version': '1.1.1'}}, 'arm_type': 'model_version', 'type': 'mlflow_model'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 73,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "run_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 74,
          "data": {
            "text/plain": "Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': True, 'name': 'run-model-example', 'description': 'Model created from run.', 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/Chapter6', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f062546fbe0>, 'version': None, 'latest_version': None, 'path': 'azureml://jobs/coral_gas_1hz6njncjl/outputs/artifacts/paths/model/', 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'mlflow_model'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 74,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "run_model.path"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 75,
          "data": {
            "text/plain": "'azureml://jobs/coral_gas_1hz6njncjl/outputs/artifacts/paths/model/'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 75,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#'path': 'azureml://subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/aml-workspace-rg/workspaces/aml-workspace/datastores/workspaceartifactstore/paths/ExperimentRun/dcid.shy_brake_7ts0t3rj8w/model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}