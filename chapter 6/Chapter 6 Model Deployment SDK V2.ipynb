{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model to online endpoint\n",
    "\n",
    "- Models created with MLFlow do not require a scoring script nor an environment, with this notebook, we will create a scopy.py file and use that with our model.\n",
    "\n",
    "- Before running this notebook, run the **Chapter 6 Prep-Model Creation & Registration.ipynb** notebook to create and register a model for use\n",
    "\n",
    "- Models created with MLFlow do not require a scoring script nor an environment\n",
    "\n",
    "## In this notebook we will:\n",
    "\n",
    "- Connect to your workspace.\n",
    "- Create an online endpoint\n",
    "- Retrieve and register a model from the job ran in the previous notebook\n",
    "- Create a deployment\n",
    "- Make an API Call to the managed online endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import azure.ai.ml\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "\n",
    "print(azure.ai.ml._version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"b071bca8-0055-43f9-9ff8-ca9a144c2a6f\"\n",
    "resource_group = \"aml-dev-rg\"\n",
    "workspace = \"aml-dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    # This will open a browser page for\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/.azureml/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f6814daebf0>,\n",
      "         subscription_id=b071bca8-0055-43f9-9ff8-ca9a144c2a6f,\n",
      "         resource_group_name=aml-dev-rg,\n",
      "         workspace_name=aml-dev)\n"
     ]
    }
   ],
   "source": [
    "#connect to the workspace\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential=credential)\n",
    "except Exception as ex:\n",
    "    # NOTE: Update following workspace information if not correctly configure before\n",
    "    client_config = {\n",
    "        \"subscription_id\": subscription_id,\n",
    "        \"resource_group\": resource_group,\n",
    "        \"workspace_name\": workspace,\n",
    "    }\n",
    "\n",
    "    if client_config[\"subscription_id\"].startswith(\"<\"):\n",
    "        print(\n",
    "            \"please update your <SUBSCRIPTION_ID> <RESOURCE_GROUP> <AML_WORKSPACE_NAME> in notebook cell\"\n",
    "        )\n",
    "        raise ex\n",
    "    else:  # write and reload from config file\n",
    "        import json, os\n",
    "\n",
    "        config_path = \"../.azureml/config.json\"\n",
    "        os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "        with open(config_path, \"w\") as fo:\n",
    "            fo.write(json.dumps(client_config))\n",
    "        ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"ch6-sdkv2-endpt-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"titanic online endpoint for mlflow model\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"oneline endpoint\": \"titanic\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create endpoint\n",
    "\n",
    "Using the MLClient created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f68243c6da0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment\n",
    "A deployment is a set of resouces used for hosting the inferecing model using the *ManagedOnlineDeployment* class.  \n",
    "Using the *ManagedOnlineDeployment* class, a developer can configure the following components\n",
    "\n",
    "- name: name of the deployment\n",
    "- endpoint_name: name of the endpoint to create the deployment under\n",
    "- model: the model to use for the deployment\n",
    "- instance_type: the VM side to use for deployment\n",
    "- instance_count: the number of instances to use for the deployment\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Model from registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e5ccf20f-54f7-4511-8ca7-15703445747c\n",
      "sincere_shirt_95vn1fk2nc\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "experiment = 'chapter6'\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)\n",
    "\n",
    "df = mlflow.search_runs([experiment_id])\n",
    "\n",
    "\n",
    "run_id = df['run_id'].iloc[-1]\n",
    "print(run_id)\n",
    "print(type(run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sincere_shirt_95vn1fk2nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<FileInfo: file_size=-1, is_dir=False, path='estimator.html'>,\n",
       " <FileInfo: file_size=-1, is_dir=True, path='model'>,\n",
       " <FileInfo: file_size=-1, is_dir=True, path='system_logs'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='training_confusion_matrix.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='training_precision_recall_curve.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='training_roc_curve.png'>,\n",
       " <FileInfo: file_size=-1, is_dir=True, path='user_logs'>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(run_id)\n",
    "mlflow.set_experiment(experiment_name='Chapter6')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.list_artifacts(run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23870/3777299957.py:4: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  file_path = client.download_artifacts(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "file_path = client.download_artifacts(\n",
    "    run_id, path=\"model\"\n",
    ")\n",
    "shutil.copytree(file_path, './model', dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(path=\"./model/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ml_client.environments.get(name = 'job_base_env', version = \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Scoring Script\n",
    "\n",
    "score.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ManagedOnlineEndpoint folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "script_folder = 'ManagedOnlineEndpoint'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ManagedOnlineEndpoint/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/score.py\n",
    "\n",
    "import os \n",
    "import json\n",
    "import joblib\n",
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "    logging.info(\"Init complete\")\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    dict= json.loads(raw_data)\n",
    "    df = json_normalize(dict['raw_data']) \n",
    "    y_pred = model.predict(df)\n",
    "    print(type(y_pred))\n",
    "    \n",
    "    result = {\"result\": y_pred.tolist()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the deployment\n",
    "\n",
    "- retrieve the experiment id for this run, and the run id to retrieve the model from the registered model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=\"azureml:job_base_env:16\",\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./ManagedOnlineEndpoint\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_type=\"Standard_F4s_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint ch6-sdkv2-endpt-11282324567965 exists\n",
      "\u001b[32mUploading model.pkl\u001b[32m (< 1 MB): 100%|██████████| 2.62k/2.62k [00:00<00:00, 62.5kB/s]\n",
      "\u001b[39m\n",
      "\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f681430bf10>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........"
     ]
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(blue_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      "Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      "..Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      ".Updating..will take about 10 minutes to deploy...\n",
      "."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "import time\n",
    "while ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state == 'Updating':\n",
    "    print('Updating..will take about 10 minutes to deploy...')\n",
    "    time.sleep(5)\n",
    "    \n",
    "ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.core.polling._poller.LROPoller at 0x7f68143287c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "while ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state == 'Updating':\n",
    "    print('Updating')\n",
    "    time.sleep(5)\n",
    "    \n",
    "ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://ch6-sdkv2-endpt-11282324567965.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://ch6-sdkv2-endpt-11282324567965.eastus2.inference.ml.azure.com/swagger.json', 'name': 'ch6-sdkv2-endpt-11282324567965', 'description': 'titanic online endpoint for mlflow model', 'tags': {'oneline endpoint': 'titanic'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/providers/microsoft.machinelearningservices/workspaces/aml-dev/onlineendpoints/ch6-sdkv2-endpt-11282324567965', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:9634b616-29cb-4345-ae22-4be4e4bfe009:e1178544-8fe9-4b48-bf87-eb94f71c0b34?api-version=2022-02-01-preview'}, 'id': '/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourceGroups/aml-dev-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-dev/onlineEndpoints/ch6-sdkv2-endpt-11282324567965', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/chapter 6', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f68143f8a30>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f6814309d50>, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})\n",
      " \n",
      "{'blue': 100}\n",
      " \n",
      "uri: https://ch6-sdkv2-endpt-11282324567965.eastus2.inference.ml.azure.com/score\n",
      " \n",
      "primary key: 42ETJMcQh3OLJODwkbu870Y1qLVnPvIp\n"
     ]
    }
   ],
   "source": [
    "## Get Endpoint details\n",
    "\n",
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(endpoint)\n",
    "print(' ')\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "print(' ')\n",
    "# Get the scoring URI\n",
    "print('uri: ' + str(endpoint.scoring_uri))\n",
    "primary_key = ml_client.online_endpoints.get_keys(name = online_endpoint_name).primary_key\n",
    "print(' ')\n",
    "print('primary key: ' + str(primary_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev/datastores/workspaceblobstore/paths/LocalUpload/b3e9d2d76d36b52fc88b17546f0f0460/titanic_prepped_mltable/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized authentication type: None\n",
      "Unrecognized authentication type: None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>GroupSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>S</td>\n",
       "      <td>B</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>S</td>\n",
       "      <td>X</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>23.45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Q</td>\n",
       "      <td>X</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked Loc Sex Pclass   Age     Fare GroupSize\n",
       "0          S   X   m      3  22.0     7.25         2\n",
       "1          C   C   f      1  38.0  71.2833         2\n",
       "2          S   X   f      3  26.0    7.925         1\n",
       "3          S   C   f      1  35.0     53.1         2\n",
       "4          S   X   m      3  35.0     8.05         1\n",
       "..       ...  ..  ..    ...   ...      ...       ...\n",
       "886        S   X   m      2  27.0     13.0         1\n",
       "887        S   B   f      1  19.0     30.0         1\n",
       "888        S   X   f      3  21.5    23.45         4\n",
       "889        C   C   m      1  26.0     30.0         1\n",
       "890        Q   X   m      3  32.0     7.75         1\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mltable\n",
    "registered_v1_data_asset = ml_client.data.get(name='titanic_prepped_mltable_x2', version='1')\n",
    "print(registered_v1_data_asset.path)\n",
    "\n",
    "tbl = mltable.load(uri=registered_v1_data_asset.path)\n",
    "df = tbl.to_pandas_dataframe()\n",
    "\n",
    "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "X_raw           = df[columns_to_keep]\n",
    "X_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"raw_data\": [{\"Embarked\":\"S\",\"Loc\":\"X\",\"Sex\":\"m\",\"Pclass\":\"3\",\"Age\":\"22.0\",\"Fare\":\"7.25\",\"GroupSize\":\"2\"},{\"Embarked\":\"C\",\"Loc\":\"C\",\"Sex\":\"f\",\"Pclass\":\"1\",\"Age\":\"38.0\",\"Fare\":\"71.2833\",\"GroupSize\":\"2\"},{\"Embarked\":\"S\",\"Loc\":\"X\",\"Sex\":\"f\",\"Pclass\":\"3\",\"Age\":\"26.0\",\"Fare\":\"7.925\",\"GroupSize\":\"1\"},{\"Embarked\":\"S\",\"Loc\":\"C\",\"Sex\":\"f\",\"Pclass\":\"1\",\"Age\":\"35.0\",\"Fare\":\"53.1\",\"GroupSize\":\"2\"},{\"Embarked\":\"S\",\"Loc\":\"X\",\"Sex\":\"m\",\"Pclass\":\"3\",\"Age\":\"35.0\",\"Fare\":\"8.05\",\"GroupSize\":\"1\"}]}\n",
      "\n",
      "predictions\n",
      "[0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "url = endpoint.scoring_uri\n",
    "api_key = primary_key  # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "import requests\n",
    "\n",
    "def MakePrediction(df):\n",
    "    endpoint_url = url\n",
    "    body = df.to_json(orient='records') \n",
    "    body = '{\"raw_data\": ' + body + '}'\n",
    "    print(body)\n",
    "    r = requests.post(endpoint_url, headers=headers, data=body)\n",
    "    return (r.json())\n",
    "\n",
    "\n",
    "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "X_raw           = df[columns_to_keep]\n",
    "\n",
    "\n",
    "dftest = X_raw.head(5)\n",
    "\n",
    "results = MakePrediction(dftest)\n",
    "\n",
    "val = results['result']\n",
    "print('')\n",
    "print('predictions')\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "job_env"
  },
  "kernelspec": {
   "display_name": "job_env",
   "language": "python",
   "name": "job_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
