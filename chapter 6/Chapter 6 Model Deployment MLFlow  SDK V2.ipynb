{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy MLflow Model to online endpoint\n",
        "\n",
        "- Before running this notebook, run the **Chapter 6 Prep-Model Creation & Registration.ipynb** notebook to create and register a model for use\n",
        "\n",
        "- Models created with MLFlow do not require a scoring script nor an environment\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azure.ai.ml\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "\n",
        "print(azure.ai.ml._version.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1.1.1\n"
        }
      ],
      "execution_count": 36,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
        "resource_group = \"<RESOURCE_GROUP>\"\n",
        "workspace = \"<AML_WORKSPACE_NAME>\""
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    # This will open a browser page for\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to the workspace\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential)\n",
        "except Exception as ex:\n",
        "    # NOTE: Update following workspace information if not correctly configure before\n",
        "    client_config = {\n",
        "        \"subscription_id\": subscription_id,\n",
        "        \"resource_group\": resource_group,\n",
        "        \"workspace_name\": workspace,\n",
        "    }\n",
        "\n",
        "    if client_config[\"subscription_id\"].startswith(\"<\"):\n",
        "        print(\n",
        "            \"please update your <SUBSCRIPTION_ID> <RESOURCE_GROUP> <AML_WORKSPACE_NAME> in notebook cell\"\n",
        "        )\n",
        "        raise ex\n",
        "    else:  # write and reload from config file\n",
        "        import json, os\n",
        "\n",
        "        config_path = \"../.azureml/config.json\"\n",
        "        os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
        "        with open(config_path, \"w\") as fo:\n",
        "            fo.write(json.dumps(client_config))\n",
        "        ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
        "print(ml_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/.azureml/config.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f38d0111c00>,\n         subscription_id=b071bca8-0055-43f9-9ff8-ca9a144c2a6f,\n         resource_group_name=aml-dev-rg,\n         workspace_name=aml-dev)\n"
        }
      ],
      "execution_count": 39,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Online Endpoint\n",
        "\n",
        "To create an online endpoint, we will leverage the class *ManagedOnlineEndpoint*.  To create the online endpoint we will provide the following configuration:\n",
        "\n",
        "- name of endpoint\n",
        "- description\n",
        "- auth_mode (set to key) or aml_token\n",
        "- tags - to provide information regarding the endpoint"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure endpoint"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"chp6-mlflow-endpt-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "print(len(online_endpoint_name))\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"titanic online endpoint for mlflow model\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\"mlflow\": \"true\"},\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "32\n"
        }
      ],
      "execution_count": 40,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create endpoint\n",
        "\n",
        "Using the MLClient created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.begin_create_or_update(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7f390a940910>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 41,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create deployment\n",
        "A deployment is a set of resouces used for hosting the inferecing model using the *ManagedOnlineDeployment* class.  \n",
        "Using the *ManagedOnlineDeployment* class, a developer can configure the following components\n",
        "\n",
        "- name: name of the deployment\n",
        "- endpoint_name: name of the endpoint to create the deployment under\n",
        "- model: the model to use for the deployment\n",
        "- instance_type: the VM side to use for deployment\n",
        "- instance_count: the number of instances to use for the deployment\n",
        "    "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieve Model from registry"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = 'chapter6'\n",
        "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
        "experiment_id=current_experiment['experiment_id']\n",
        "print(experiment_id)\n",
        "\n",
        "df = mlflow.search_runs([experiment_id])\n",
        "\n",
        "run_id = df['run_id'].tail(1).values[0]\n",
        "print(run_id)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "e5ccf20f-54f7-4511-8ca7-15703445747c\nsincere_shirt_95vn1fk2nc\n"
        }
      ],
      "execution_count": 44,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "run_model = Model(\n",
        "    name=\"chapter6_titanic_model\",\n",
        "    path=\"azureml://jobs/\" + run_id + \"/outputs/artifacts/paths/model/\",\n",
        "    description=\"Model created from run.\",\n",
        "    type=AssetTypes.MLFLOW_MODEL \n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "run_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': True, 'name': 'chapter6_titanic_model', 'description': 'Model created from run.', 'tags': {}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/chapter 6', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f3887071db0>, 'version': None, 'latest_version': None, 'path': 'azureml://jobs/sincere_shirt_95vn1fk2nc/outputs/artifacts/paths/model/', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'mlflow_model'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure the deployment\n",
        "\n",
        "- retrieve the experiment id for this run, and the run id to retrieve the model from the registered model list"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "while ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state == 'Creating':\n",
        "    print('Creating')\n",
        "    time.sleep(10)\n",
        "\n",
        "print(ml_client.online_endpoints.get(name=online_endpoint_name).provisioning_state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Succeeded\n"
        }
      ],
      "execution_count": 47,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=run_model,\n",
        "    instance_type=\"Standard_F4s_v2\",\n",
        "    instance_count=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Create deployment\n",
        "print(online_endpoint_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "chp6-mlflow-endpt-11282304439097\n"
        }
      ],
      "execution_count": 49,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.begin_create_or_update(blue_deployment)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint chp6-mlflow-endpt-11282304439097 exists\ndata_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x7f3887072740>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 50,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "while ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state == 'Updating':\n",
        "    print('Updating..will take about 10 minutes to deploy...')\n",
        "    time.sleep(5)\n",
        "    \n",
        "ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n..Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n..Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.Updating\n.."
        },
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "'Succeeded'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## get status of online deployment\n",
        "ml_client.online_deployments.get_logs(\n",
        "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": "\"Instance status:\\nSystemSetup: Succeeded\\nUserContainerImagePull: Succeeded\\nModelDownload: Succeeded\\nUserContainerStart: Succeeded\\n\\nContainer events:\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:16.811423Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:26.207871Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:26.811525Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:36.207687Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:36.81158Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:46.207747Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:46.811414Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:56.207632Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:12:56.811392Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:06.208147Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:06.843415Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:16.207401Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:16.811325Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:26.207796Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:26.811542Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:36.207775Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:36.811369Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: LivenessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:46.207759Z, Message: Liveness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ReadinessProbeFailed, Type: Warning, Time: 2022-11-28T23:13:46.811299Z, Message: Readiness probe failed: HTTP probe failed with statuscode: 502\\nKind: Pod, Name: ContainerReady, Type: Normal, Time: 2022-11-28T23:13:57.154816523Z, Message: Container is ready\\n\\nContainer logs:\\nSuccessfully installed azure-core-1.26.1 azure-identity-1.12.0 azureml-inference-server-http-0.7.6 cachetools-5.2.0 cffi-1.15.1 cryptography-38.0.4 flask-2.1.3 flask-cors-3.0.10 google-api-core-2.10.2 google-auth-2.14.1 googleapis-common-protos-1.57.0 inference-schema-1.4.2.1 msal-1.20.0 msal-extensions-1.0.0 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 portalocker-2.6.0 psutil-5.9.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 rsa-4.9 typing-extensions-4.4.0 wrapt-1.12.1\\n2022-11-28T23:13:52,192487662+00:00 | gunicorn/run | \\n2022-11-28T23:13:52,194264267+00:00 | gunicorn/run | ###############################################\\n2022-11-28T23:13:52,195968371+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\\n2022-11-28T23:13:52,197523876+00:00 | gunicorn/run | ###############################################\\n2022-11-28T23:13:52,199154980+00:00 | gunicorn/run | \\n2022-11-28T23:13:52,879023371+00:00 | gunicorn/run | \\n2022-11-28T23:13:52,881071976+00:00 | gunicorn/run | ###############################################\\n2022-11-28T23:13:52,883040382+00:00 | gunicorn/run | AzureML Inference Server\\n2022-11-28T23:13:52,884874787+00:00 | gunicorn/run | ###############################################\\n2022-11-28T23:13:52,886723492+00:00 | gunicorn/run | \\n2022-11-28T23:13:52,888526197+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\n\\nAzure ML Inferencing HTTP server v0.7.6\\n\\n\\nServer Settings\\n---------------\\nEntry Script Name: /var/mlflow_resources/mlflow_score_script.py\\nModel Directory: /var/azureml-app/azureml-models/chapter6_titanic_model/13\\nWorker Count: 1\\nWorker Timeout (seconds): 300\\nServer Port: 31311\\nApplication Insights Enabled: false\\nApplication Insights Key: None\\nInferencing HTTP server version: azmlinfsrv/0.7.6\\nCORS for the specified origins: None\\n\\n\\nServer Routes\\n---------------\\nLiveness Probe: GET   127.0.0.1:31311/\\nScore:          POST  127.0.0.1:31311/score\\n\\nStarting gunicorn 20.1.0\\nListening at: http://0.0.0.0:31311 (9)\\nUsing worker: sync\\nBooting worker with pid: 695\\nInitializing logger\\n2022-11-28 23:13:53,392 | root | INFO | Starting up app insights client\\nlogging socket not found. logging not available.\\nlogging socket not found. logging not available.\\n2022-11-28 23:13:53,392 | root | INFO | Starting up app insight hooks\\n2022-11-28 23:13:54,497 | root | INFO | Found user script at /var/mlflow_resources/mlflow_score_script.py\\n2022-11-28 23:13:54,497 | root | INFO | run() is decorated with @input_schema. Server will invoke it with the following arguments: input_data.\\n2022-11-28 23:13:54,497 | root | INFO | Invoking user's init function\\n2022-11-28 23:13:54,497 | root | INFO | Users's init has completed successfully\\n2022-11-28 23:13:54,498 | root | INFO | Swaggers are prepared for versions [3] and skipped for versions [2].\\n2022-11-28 23:13:54,498 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\n2022-11-28 23:13:54,498 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\n\\n\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 53,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# blue deployment takes 100 traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.begin_create_or_update(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExistsError",
          "evalue": "(Conflict) Conflict\nCode: Conflict\nMessage: Conflict\nException Details:\t(OperationDuplicationConflict) Conflict of operation, another operation on same entity is already running in workspace aml-dev.\n\tCode: OperationDuplicationConflict\n\tMessage: Conflict of operation, another operation on same entity is already running in workspace aml-dev.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExistsError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# blue deployment takes 100 traffic\u001b[39;00m\n\u001b[1;32m      2\u001b[0m endpoint\u001b[38;5;241m.\u001b[39mtraffic \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m}\n\u001b[0;32m----> 3\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/ai/ml/_ml_client.py:841\u001b[0m, in \u001b[0;36mMLClient.begin_create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbegin_create_or_update\u001b[39m(\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    816\u001b[0m     entity: R,\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    818\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LROPoller[R]:\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;124;03m\"\"\"Creates or updates an Azure ML resource asynchronously.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m        azure.ai.ml.entities.JobSchedule]]\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_begin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_operation_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    887\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/ai/ml/_ml_client.py:923\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, *args, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;129m@_begin_create_or_update\u001b[39m\u001b[38;5;241m.\u001b[39mregister(OnlineEndpoint)\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(entity: OnlineEndpoint, operations, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    922\u001b[0m     module_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating or updating online_endpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAzureMLResourceType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mONLINE_ENDPOINT\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:259\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[0;32m--> 259\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/ai/ml/operations/_online_endpoint_operations.py:258\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.begin_create_or_update\u001b[0;34m(self, endpoint, local)\u001b[0m\n\u001b[1;32m    256\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/ai/ml/operations/_online_endpoint_operations.py:253\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.begin_create_or_update\u001b[0;34m(self, endpoint, local)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m poller\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ex, (ValidationException, SchemaValidationError)):\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/ai/ml/operations/_online_endpoint_operations.py:242\u001b[0m, in \u001b[0;36mOnlineEndpointOperations.begin_create_or_update\u001b[0;34m(self, endpoint, local)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(endpoint_resource\u001b[38;5;241m.\u001b[39mproperties, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    238\u001b[0m         endpoint_resource\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mcompute \u001b[38;5;241m=\u001b[39m orchestrators\u001b[38;5;241m.\u001b[39mget_asset_arm_id(\n\u001b[1;32m    239\u001b[0m             endpoint_resource\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mcompute,\n\u001b[1;32m    240\u001b[0m             azureml_type\u001b[38;5;241m=\u001b[39mAzureMLResourceType\u001b[38;5;241m.\u001b[39mCOMPUTE,\n\u001b[1;32m    241\u001b[0m         )\n\u001b[0;32m--> 242\u001b[0m     poller \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_online_operation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeserialized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOnlineEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_rest_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeserialized\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m poller\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_endpoints_operations.py:921\u001b[0m, in \u001b[0;36mOnlineEndpointsOperations.begin_create_or_update\u001b[0;34m(self, resource_group_name, workspace_name, endpoint_name, body, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m cont_token \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinuation_token\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# type: Optional[str]\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cont_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 921\u001b[0m     raw_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_or_update_initial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mz\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_map\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_long_running_output\u001b[39m(pipeline_response):\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2022_02_01_preview/operations/_online_endpoints_operations.py:855\u001b[0m, in \u001b[0;36mOnlineEndpointsOperations._create_or_update_initial\u001b[0;34m(self, resource_group_name, workspace_name, endpoint_name, body, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m201\u001b[39m]:\n\u001b[0;32m--> 855\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, error_format\u001b[38;5;241m=\u001b[39mARMErrorFormat)\n\u001b[1;32m    858\u001b[0m response_headers \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/anaconda/envs/job_env/lib/python3.10/site-packages/azure/core/exceptions.py:107\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    106\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
            "\u001b[0;31mResourceExistsError\u001b[0m: (Conflict) Conflict\nCode: Conflict\nMessage: Conflict\nException Details:\t(OperationDuplicationConflict) Conflict of operation, another operation on same entity is already running in workspace aml-dev.\n\tCode: OperationDuplicationConflict\n\tMessage: Conflict of operation, another operation on same entity is already running in workspace aml-dev."
          ]
        }
      ],
      "execution_count": 55,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking provisioning state"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "while ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state == 'Updating':\n",
        "    print('Updating')\n",
        "    time.sleep(5)\n",
        "    \n",
        "ml_client.online_deployments.get(name = \"blue\", endpoint_name = online_endpoint_name).provisioning_state"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 56,
          "data": {
            "text/plain": "'Succeeded'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 56,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Endpoint details"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "print(endpoint)\n",
        "\n",
        "# existing traffic details\n",
        "print(endpoint.traffic)\n",
        "\n",
        "# Get the scoring URI\n",
        "print(endpoint.scoring_uri)\n",
        "\n",
        "primary_key = ml_client.online_endpoints.get_keys(name = online_endpoint_name).primary_key\n",
        "\n",
        "print(primary_key)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://chp6-mlflow-endpt-11282304439097.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://chp6-mlflow-endpt-11282304439097.eastus2.inference.ml.azure.com/swagger.json', 'name': 'chp6-mlflow-endpt-11282304439097', 'description': 'titanic online endpoint for mlflow model', 'tags': {'mlflow': 'true'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/providers/microsoft.machinelearningservices/workspaces/aml-dev/onlineendpoints/chp6-mlflow-endpt-11282304439097', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:9634b616-29cb-4345-ae22-4be4e4bfe009:20a39653-046b-4b29-822a-af866773cfb9?api-version=2022-02-01-preview'}, 'id': '/subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourceGroups/aml-dev-rg/providers/Microsoft.MachineLearningServices/workspaces/aml-dev/onlineEndpoints/chp6-mlflow-endpt-11282304439097', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/memasanz1/code/Users/memasanz/ML-Engineering-with-Azure-Machine-Learning-Service/chapter 6', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f38863a8be0>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f38d4e7a3b0>, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})\n{'blue': 100}\nhttps://chp6-mlflow-endpt-11282304439097.eastus2.inference.ml.azure.com/score\nwFPQWYJSe5XDFpxpbjaV51EPaGI06vgc\n"
        }
      ],
      "execution_count": 57,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leverage the registered ml table from Chapter 4 to get some data to send to the rest endpoint.\n",
        "\n",
        "- Previously in Chapter 4, we registered the MLTable: titanic_prepped_mltable_x2, we will retrieve it and convert it to a pandas datafame"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mltable\n",
        "registered_v1_data_asset = ml_client.data.get(name='titanic_prepped_mltable_x2', version='1')\n",
        "print(registered_v1_data_asset.path)\n",
        "\n",
        "tbl = mltable.load(uri=registered_v1_data_asset.path)\n",
        "df = tbl.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml://subscriptions/b071bca8-0055-43f9-9ff8-ca9a144c2a6f/resourcegroups/aml-dev-rg/workspaces/aml-dev/datastores/workspaceblobstore/paths/LocalUpload/b3e9d2d76d36b52fc88b17546f0f0460/titanic_prepped_mltable/\n"
        }
      ],
      "execution_count": 58,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
        "X_raw           = df[columns_to_keep]\n",
        "X_raw"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Embarked</th>\n      <th>Loc</th>\n      <th>Sex</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>GroupSize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>S</td>\n      <td>X</td>\n      <td>m</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>7.25</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C</td>\n      <td>C</td>\n      <td>f</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>71.2833</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>S</td>\n      <td>X</td>\n      <td>f</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>7.925</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>S</td>\n      <td>C</td>\n      <td>f</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>53.1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>S</td>\n      <td>X</td>\n      <td>m</td>\n      <td>3</td>\n      <td>35.0</td>\n      <td>8.05</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>S</td>\n      <td>X</td>\n      <td>m</td>\n      <td>2</td>\n      <td>27.0</td>\n      <td>13.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>S</td>\n      <td>B</td>\n      <td>f</td>\n      <td>1</td>\n      <td>19.0</td>\n      <td>30.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>S</td>\n      <td>X</td>\n      <td>f</td>\n      <td>3</td>\n      <td>21.5</td>\n      <td>23.45</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>C</td>\n      <td>C</td>\n      <td>m</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>30.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>Q</td>\n      <td>X</td>\n      <td>m</td>\n      <td>3</td>\n      <td>32.0</td>\n      <td>7.75</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 7 columns</p>\n</div>",
            "text/plain": "    Embarked Loc Sex Pclass   Age     Fare GroupSize\n0          S   X   m      3  22.0     7.25         2\n1          C   C   f      1  38.0  71.2833         2\n2          S   X   f      3  26.0    7.925         1\n3          S   C   f      1  35.0     53.1         2\n4          S   X   m      3  35.0     8.05         1\n..       ...  ..  ..    ...   ...      ...       ...\n886        S   X   m      2  27.0     13.0         1\n887        S   B   f      1  19.0     30.0         1\n888        S   X   f      3  21.5    23.45         4\n889        C   C   m      1  26.0     30.0         1\n890        Q   X   m      3  32.0     7.75         1\n\n[891 rows x 7 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 59,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "url = endpoint.scoring_uri\n",
        "api_key = primary_key  # Replace this with the API key for the web service\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'blue' }\n",
        "import requests\n",
        "\n",
        "def MakePrediction(df):\n",
        "    strjson = str(df.to_json(orient='records'))\n",
        "    endpoint_url = url\n",
        "\n",
        "    request_data =  {\n",
        "              \"input_data\": {\n",
        "                \"columns\": [\n",
        "                  \"Embarked\",\n",
        "                  \"Loc\",\n",
        "                  \"Sex\",\n",
        "                  \"Pclass\",\n",
        "                  \"Age\",\n",
        "                  \"Fare\",\n",
        "                  \"GroupSize\"\n",
        "                ],\n",
        "                \"data\": []\n",
        "              }\n",
        "            }\n",
        "\n",
        "    request_data['input_data']['data'] = json.loads(X_raw.to_json(orient='records'))\n",
        "    parsed = json.dumps(request_data)\n",
        "    \n",
        "    r = requests.post(endpoint_url, headers=headers, data=parsed)\n",
        "    return (r.json())\n",
        "\n",
        "results = MakePrediction(X_raw)\n",
        "print(results)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n"
        }
      ],
      "execution_count": 60,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "job_env"
    },
    "kernelspec": {
      "name": "job_env",
      "language": "python",
      "display_name": "job_env"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}