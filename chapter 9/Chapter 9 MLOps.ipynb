{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps with CLI V2\n",
    "\n",
    "- Creating Scripts for MLOps Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mlflow azureml-mlflow\n",
    "#https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics?tabs=interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5da07161-3770-4a4b-aa43-418cbbb627cf\n"
     ]
    }
   ],
   "source": [
    "# subscription_id = '<SUBSCRIPTION_ID>'\n",
    "# resource_group= '<resource_group>'\n",
    "# workspace = '<workspace>'\n",
    "\n",
    "subscription_id = '5da07161-3770-4a4b-aa43-418cbbb627cf'\n",
    "resource_group = 'aml-dev-rg'\n",
    "workspace = 'aml-dev'\n",
    "\n",
    "\n",
    "# os.environ.setdefault('subscription_id', subscription_id)\n",
    "# os.environ.setdefault('resource_group', resource_group)\n",
    "# os.environ.setdefault('workspace', workspace)\n",
    "\n",
    "# subscription_id = os.environ.get('subscription_id')\n",
    "# resource_group = os.environ.get('resource_group')\n",
    "# workspace = os.environ.get('workspace')\n",
    "\n",
    "print(subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.entities import Environment, BuildContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./src/ src folder created\n",
      "./src/prep prep folder created\n",
      "./src/train train folder created\n",
      "./src/eval eval folder created\n",
      "./src/deploy deploy folder created\n",
      "./src/pipeline pipeline folder created\n",
      "./src/conda-yamls conda-yamls folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "script_folder = './src/'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'src folder created')\n",
    "\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "script_folder = './src/prep'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'prep folder created')\n",
    "\n",
    "script_folder = './src/train'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'train folder created')\n",
    "\n",
    "script_folder = './src/eval'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'eval folder created')\n",
    "\n",
    "script_folder = './src/deploy'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'deploy folder created')\n",
    "\n",
    "script_folder = './src/pipeline'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'pipeline folder created')\n",
    "\n",
    "script_folder = './src/conda-yamls'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'conda-yamls folder created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/conda-yamls/pipeline_conda_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/conda-yamls/pipeline_conda_env.yml\n",
    "name: job_env\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.8.5\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow\n",
    "  - azureml-mlflow\n",
    "  - azure-ai-ml\n",
    "  - mltable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    # This will open a browser page for\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ../.azureml/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subscription_id': '5da07161-3770-4a4b-aa43-418cbbb627cf', 'resource_group': 'aml-dev-rg', 'workspace_name': 'aml-dev'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def force_login():\n",
    "    \n",
    "    config_path = \"../.azureml/config.json\"\n",
    "    os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "        \n",
    "    client_config = {\n",
    "        \"subscription_id\": subscription_id,\n",
    "        \"resource_group\": resource_group,\n",
    "        \"workspace_name\": workspace,\n",
    "    }\n",
    "    \n",
    "    with open(config_path, \"w\") as fo:\n",
    "            fo.write(json.dumps(client_config))\n",
    "    ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
    "    \n",
    "    print(client_config)\n",
    "    \n",
    "force_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/mmcompute-instance/code/Users/memasanz/mlops/.azureml/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x7f6ed6f87c70>,\n",
      "         subscription_id=5da07161-3770-4a4b-aa43-418cbbb627cf,\n",
      "         resource_group_name=aml-dev-rg,\n",
      "         workspace_name=aml-dev)\n"
     ]
    }
   ],
   "source": [
    "#connect to the workspace\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential=credential)\n",
    "except Exception as ex:\n",
    "    # NOTE: Update following workspace information if not correctly configure before\n",
    "    client_config = {\n",
    "        \"subscription_id\": subscription_id,\n",
    "        \"resource_group\": resource_group,\n",
    "        \"workspace_name\": workspace,\n",
    "    }\n",
    "\n",
    "    if client_config[\"subscription_id\"].startswith(\"<\"):\n",
    "        print(\n",
    "            \"please update your <SUBSCRIPTION_ID> <RESOURCE_GROUP> <AML_WORKSPACE_NAME> in notebook cell\"\n",
    "        )\n",
    "        raise ex\n",
    "    else:  # write and reload from config file\n",
    "        import json, os\n",
    "\n",
    "        config_path = \"../.azureml/config.json\"\n",
    "        os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "        with open(config_path, \"w\") as fo:\n",
    "            fo.write(json.dumps(client_config))\n",
    "        ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# client = mlflow.tracking.MlflowClient()\n",
    "# client.list_artifacts(\"000d6ec3-533a-4ed7-8644-667da5d7a8d8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "data asset is registered\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('./data/titanic.csv')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "try:\n",
    "    registered_data_asset = ml_client.data.get(name='titanic_raw', version=1)\n",
    "    print('data asset is registered')\n",
    "except:\n",
    "    print('register data asset')\n",
    "    my_data = Data(\n",
    "        path=\"./data/titanic.csv\",\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Titanic CSV\",\n",
    "        name=\"titanic_raw\",\n",
    "        version=\"1\",\n",
    "    )\n",
    "\n",
    "    ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Scripts for Training Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/prep/prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/prep/prep.py\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "parser = argparse.ArgumentParser(\"prep\")\n",
    "parser.add_argument(\"--raw_data\", type=str, help=\"Path to raw data\")\n",
    "parser.add_argument(\"--prep_data\", type=str, help=\"Path of prepped data\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args.raw_data)\n",
    "print(args.prep_data)\n",
    "\n",
    "df = pd.read_csv(args.raw_data + '/titanic.csv')\n",
    "\n",
    "df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "df['Sex']= df['Sex'].apply(lambda x: x[0] if pd.notnull(x) else 'X')\n",
    "df['Loc']= df['Cabin'].apply(lambda x: x[0] if pd.notnull(x) else 'X')\n",
    "df.drop(['Cabin', 'Ticket'], axis=1, inplace=True)\n",
    "df['Embarked'] = df['Embarked'].fillna('S')\n",
    "df.loc[:,'GroupSize'] = 1 + df['SibSp'] + df['Parch']\n",
    "\n",
    "LABEL = 'Survived'\n",
    "df_train = df\n",
    "df = df_train.drop(['Name','SibSp', 'Parch', 'PassengerId'], axis=1)\n",
    "\n",
    "df.to_csv(args.prep_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/train/train.py\n",
    "import os\n",
    "import mlflow\n",
    "import argparse\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import shutil\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# define functions\n",
    "def main(args):\n",
    "    # enable auto logging\n",
    "    current_run = mlflow.start_run()\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # read in data\n",
    "    print('about to read file:' + args.prep_data)\n",
    "    df = pd.read_csv(args.prep_data)\n",
    "    #model, X_test = model_train('Survived', df, args.randomstate)\n",
    "    model, X_test, y_test = model_train('Survived', df, 0)\n",
    "    \n",
    "    model_file = os.path.join(args.model_output, 'titanic_model.pkl')\n",
    "    joblib.dump(value=model, filename=model_file)\n",
    "    \n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    y_test.to_csv('outputs/Y_test.csv', index = False)\n",
    "    X_test.to_csv( 'outputs/X_test.csv', index = False)\n",
    "    shutil.copytree('./outputs/', args.test_data, dirs_exist_ok=True)\n",
    "    #maybe do mlflow logmodel\n",
    "    mlflow.sklearn.log_model(model, \"championmodel\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def model_train(LABEL, df, randomstate):\n",
    "    print('df.columns = ')\n",
    "    print(df.columns)\n",
    "    y_raw           = df[LABEL]\n",
    "    columns_to_keep = ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "    X_raw           = df[columns_to_keep]\n",
    "    \n",
    "    X_raw['Embarked'] = X_raw['Embarked'].astype(object)\n",
    "    X_raw['Loc'] = X_raw['Loc'].astype(object)\n",
    "    X_raw['Loc'] = X_raw['Sex'].astype(object)\n",
    "    X_raw['Pclass'] = X_raw['Pclass'].astype(float)\n",
    "    X_raw['Age'] = X_raw['Age'].astype(float)\n",
    "    X_raw['Fare'] = X_raw['Fare'].astype(float)\n",
    "    X_raw['GroupSize'] = X_raw['GroupSize'].astype(float)\n",
    "    \n",
    "\n",
    "\n",
    "    print(X_raw.columns)\n",
    "     # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=args.randomstate)\n",
    "    \n",
    "    #use Logistic Regression estimator from scikit learn\n",
    "    lg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    preprocessor = buildpreprocessorpipeline(X_train)\n",
    "    \n",
    "    #estimator instance\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', lg)], verbose=True)\n",
    "\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    \n",
    "    print('type of X_test = ' + str(type(X_test)))\n",
    "          \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print('*****X_test************')\n",
    "    print(X_test)\n",
    "    \n",
    "    metrics = mlflow.sklearn.eval_and_log_metrics(model, X_test, y_test, prefix=\"test_\")\n",
    "    \n",
    "    #get the active run.\n",
    "    run = mlflow.active_run()\n",
    "    print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "    MlflowClient().log_metric(run.info.run_id, \"metric\", 0.22)\n",
    "\n",
    "    \n",
    "    return model, X_test, y_test\n",
    "\n",
    "    #mlflow.end_run()\n",
    "\n",
    "\n",
    "def buildpreprocessorpipeline(X_raw):\n",
    "\n",
    "    categorical_features = X_raw.select_dtypes(include=['object', 'bool']).columns\n",
    "    numeric_features = X_raw.select_dtypes(include=['float','int64']).columns\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('onehotencoder', \n",
    "                                               OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "    numeric_transformer1 = Pipeline(steps=[('scaler1', SimpleImputer(missing_values=np.nan, strategy = 'mean'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric1', numeric_transformer1, numeric_features),\n",
    "            ('categorical', categorical_transformer, categorical_features)], remainder='drop')\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--prep_data\", default=\"data\", type=str, help=\"Path to prepped data, default to local folder\")\n",
    "    parser.add_argument(\"--input_file_name\", type=str, default=\"titanic.csv\")\n",
    "    parser.add_argument(\"---randomstate\", type=int, default=42)\n",
    "#     \n",
    "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\n",
    "    parser.add_argument(\"--test_data\", type=str,)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "    print(args.prep_data)\n",
    "    print(args.input_file_name)\n",
    "    print(args.randomstate)\n",
    "    print(args.model_output)\n",
    "    print(args.test_data)\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/eval/evaluatemodel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/eval/evaluatemodel.py\n",
    "import os\n",
    "import mlflow\n",
    "import argparse\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import shutil\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from azureml.core import Run\n",
    "from azureml.core import Model\n",
    "\n",
    "    \n",
    "    \n",
    "# define functions\n",
    "def main(args):\n",
    "    \n",
    "    model_name = args.model_name\n",
    "    \n",
    "    run = Run.get_context()\n",
    "    ws = run.experiment.workspace\n",
    "    run_id = run.id\n",
    "    print('run_id =' + run_id)\n",
    "    model_list = Model.list(ws, name=model_name, latest=True)\n",
    "    first_registration = len(model_list)==0\n",
    "    current_model = None\n",
    "        \n",
    "    # read in data\n",
    "    print('about to read file:' + args.test_data)\n",
    "    X_test = pd.read_csv(args.test_data + '/X_test.csv')\n",
    "    df_y_test = pd.read_csv(args.test_data + '/Y_test.csv')\n",
    "    y_test  = df_y_test.values.flatten()\n",
    "    #load champion model\n",
    "    model_file = os.path.join(args.model_folder, 'titanic_model.pkl')\n",
    "    champion_model = joblib.load(model_file)\n",
    "    \n",
    "    y_pred_current = champion_model.predict(X_test)\n",
    "    print('y_pred_current')\n",
    "    print(y_pred_current)\n",
    "    print('y_test')\n",
    "    print(y_test)\n",
    "    \n",
    "    champion_auc = roc_auc_score(y_test,y_pred_current)\n",
    "    print('champion_auc:' , champion_auc)\n",
    "    \n",
    "    champion_acc = np.average(y_pred_current == y_test)\n",
    "    print('champion_acc:', champion_acc)\n",
    "\n",
    "\n",
    "    \n",
    "    try:\n",
    "        current_model_aml = Model(ws,args.model_name)\n",
    "        os.makedirs(\"current_model\", exist_ok=True)\n",
    "        current_model_aml.download(\"current_model\",exist_ok=True)\n",
    "        current_model = mlflow.sklearn.load_model(os.path.join(\"current_model\",args.model_name))\n",
    "    except:\n",
    "        print('no model register with name' + args.model_name)\n",
    "        pass\n",
    "    \n",
    "    if current_model:\n",
    "        y_pred_current = current_model.predict(X_test)\n",
    "        current_acc = np.average(y_pred_current == y_test)\n",
    "        print('current_acc:', current_acc)\n",
    "        if champion_acc >= current_acc:\n",
    "            print('better model found, registering')\n",
    "            mlflow.sklearn.log_model(champion_model,args.model_name)\n",
    "            model_uri = f'runs:/{run_id}/{args.model_name}'\n",
    "            mlflow.register_model(model_uri,args.model_name)\n",
    "            \n",
    "        else:\n",
    "            print('current model performs better than champion model ')\n",
    "            print('champion_acc:', champion_acc)\n",
    "            print('current_acc:', current_acc)\n",
    "    else:\n",
    "        print('no current model')\n",
    "        print(\"First time model train, registering\")\n",
    "        mlflow.sklearn.log_model(champion_model,args.model_name)\n",
    "        model_uri = f'runs:/{run_id}/{args.model_name}'\n",
    "        mlflow.register_model(model_uri,args.model_name)\n",
    "        \n",
    "        print('hello')\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--test_data\", default=\"data\", type=str, help=\"Path to test data\")\n",
    "    parser.add_argument(\"--model_folder\", default=\"data\", type=str, help=\"Path to model data\")\n",
    "    parser.add_argument(\"--model_name\",default='mmchapter9titanic',type=str, help=\"Name of the model in workspace\")\n",
    "\n",
    "    parser.add_argument(\"--model_deployment_files\", default=\"data\", type=str, help=\"Path to model data\")\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(args.test_data)\n",
    "    print(args.model_folder)\n",
    "    print(args.model_name)\n",
    "        \n",
    "    return args\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to add:\n",
    "\n",
    "# settings:\n",
    "#   default_datastore: azureml:workspaceblobstore\n",
    "#   continue_on_step_failure: false\n",
    "#   force_rerun: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/pipeline/aml_test_pipeline.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/pipeline/aml_test_pipeline.yml\n",
    "\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\n",
    "type: pipeline\n",
    "display_name: hello_pipeline\n",
    "jobs:\n",
    "  hello_job:\n",
    "    command: echo \"hello\"\n",
    "    environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
    "    compute: azureml:cluster1\n",
    "  world_job:\n",
    "    command: echo \"world\"\n",
    "    environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
    "    compute: azureml:cluster1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/pipeline/aml_train_and_eval_pipeline.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/pipeline/aml_train_and_eval_pipeline.yml\n",
    "\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\n",
    "type: pipeline\n",
    "display_name: Training_and_eval_pipeline\n",
    "compute: azureml:cpu-cluster\n",
    "\n",
    "jobs:\n",
    "  prep_job:\n",
    "    type: command\n",
    "    code: ../prep\n",
    "    command: >-\n",
    "      python prep.py \n",
    "      --raw_data ${{inputs.raw_data}}\n",
    "      --prep_data ${{outputs.prep_data}}\n",
    "    inputs:\n",
    "      raw_data:\n",
    "        type: uri_folder\n",
    "        path: azureml:titanic_raw:1\n",
    "        mode: ro_mount\n",
    "    outputs:\n",
    "      prep_data:\n",
    "        type: uri_file\n",
    "        path: azureml://datastores/workspaceblobstore/paths/titanic_prep_data/titanic_prepped.csv\n",
    "        mode: rw_mount\n",
    "    environment:\n",
    "      conda_file: ../conda-yamls/pipeline_conda_env.yml\n",
    "      image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\n",
    "\n",
    "    \n",
    "  train_job:\n",
    "    type: command\n",
    "    inputs:\n",
    "      prep_data: ${{parent.jobs.prep_job.outputs.prep_data}}\n",
    "    outputs:\n",
    "      model_output:\n",
    "        type: uri_folder\n",
    "        path: azureml://datastores/workspaceblobstore/paths/titanic_model_data/\n",
    "        mode: rw_mount\n",
    "      test_data: \n",
    "        type: uri_folder\n",
    "        path: azureml://datastores/workspaceblobstore/paths/titanic_test_data/\n",
    "        mode: rw_mount\n",
    "    code: ../train\n",
    "    environment:\n",
    "      conda_file: ../conda-yamls/pipeline_conda_env.yml\n",
    "      image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\n",
    "    compute: azureml:cpu-cluster\n",
    "    command: >-\n",
    "      python train.py \n",
    "      --prep_data ${{inputs.prep_data}} \n",
    "      --model_output ${{outputs.model_output}}\n",
    "      --test_data ${{outputs.test_data}}\n",
    "\n",
    "  eval_job:\n",
    "    type: command\n",
    "    inputs:\n",
    "      test_data: ${{parent.jobs.train_job.outputs.test_data}}\n",
    "      model_folder: ${{parent.jobs.train_job.outputs.model_output}}\n",
    "    outputs:\n",
    "      model_deployment_files:\n",
    "        type: uri_folder\n",
    "        path: azureml://datastores/workspaceblobstore/paths/titanic_model_deployment_files/\n",
    "        mode: rw_mount\n",
    "    code: ../eval\n",
    "    environment:\n",
    "      conda_file: ../conda-yamls/pipeline_conda_env.yml\n",
    "      image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\n",
    "    compute: azureml:cpu-cluster\n",
    "    command: >-\n",
    "      python evaluatemodel.py \n",
    "      --test_data ${{inputs.test_data}} \n",
    "      --model_folder ${{inputs.model_folder}}\n",
    "      --model_deployment_files $${{outputs.model_deployment_files}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Deployment files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be sure to change your endpoint name to be something that wil be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/deploy/create-endpoint.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/deploy/create-endpoint.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json \n",
    "name: chapter9titanicendpoint3\n",
    "auth_mode: key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be sure to change your endpoint name to match the endpoint name in the `create-endpoint.yml` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/deploy/model_deployment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/deploy/model_deployment.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json \n",
    "name: green\n",
    "endpoint_name: chapter9titanicendpoint3\n",
    "model: azureml:mmchapter9titanic@latest \n",
    "instance_type: Standard_DS2_v2 \n",
    "instance_count: 2  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/AzureDevOpsPipeline.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./src/AzureDevOpsPipeline.yml\n",
    "\n",
    "resources:\n",
    "  containers:\n",
    "  - container: mlops\n",
    "    image: mcr.microsoft.com/mlops/python:latest\n",
    "\n",
    "pr: none\n",
    "trigger:\n",
    "  branches:\n",
    "    include:\n",
    "    - main\n",
    "\n",
    "variables:\n",
    "- group: devops-variable-group-dev\n",
    "- group: devops-variable-group-qa\n",
    "- name: model_name\n",
    "  value: mmchapter9titanic\n",
    "- name: ENDPT_NAME\n",
    "  value: chapter9titanicendpoint3\n",
    "- name: BLUE_DEPLOYMENT_NAME\n",
    "  value: blue\n",
    "- name: GREEN_DEPLOYMENT_NAME\n",
    "  value: green\n",
    "\n",
    "\n",
    "\n",
    "pool:\n",
    "  vmImage: ubuntu-latest\n",
    "\n",
    "stages:        \n",
    "- stage: 'testonly'\n",
    "  variables:\n",
    "  - group: devops-variable-group-qa\n",
    "  displayName: 'QAPromoteModel'\n",
    "  jobs:\n",
    "  - job: \"RegisterModelQA\"\n",
    "    steps:\n",
    "      - task: AzureCLI@1\n",
    "        env:\n",
    "          wsName: $(wsName)\n",
    "          resourceGroup: $(resourceGroup)\n",
    "          location: $(location)\n",
    "        inputs:\n",
    "          azureSubscription: aml-qa\n",
    "          scriptLocation: inlineScript\n",
    "          workingDirectory: '$(Build.SourcesDirectory)'\n",
    "          inlineScript: |\n",
    "            export NEW_DEPLOYMENT_NAME=deployment`echo $(date +\"%s\")`\n",
    "            echo $NEW_DEPLOYMENT_NAME\n",
    "            \n",
    "            az extension add -n ml -y\n",
    "            az version\n",
    "            #check if the endpoint already exists or not.\n",
    "            #if it doesn't exist, create 2 online deployments, so you can always swap between 2, one if for prod, and one is for the swap\n",
    "\n",
    "            ENDPOINT_EXISTS=$(az ml online-endpoint list -g $(resourceGroup) -w $(wsName) -o tsv --query \"[?name=='$ENDPT_NAME'][name]\" |  wc -l)\n",
    "            if [[ ENDPOINT_EXISTS -ne 1 ]]; then\n",
    "                echo \"endpoint does not exists\"\n",
    "                az ml online-endpoint create --file Chapter09/src/deploy/create-endpoint.yml -g $(resourceGroup) -w $(wsName)\n",
    "                #deploy to both blue and green, so there will always be a blue and a green to swap between\n",
    "                #az ml online-deployment create --name $BLUE_DEPLOYMENT_NAME -f Chapter09/src/deploy/model_deployment.yml -g $(resourceGroup) -w $(wsName)\n",
    "                #arbitrarily deploy the green endpoint since neither exists\n",
    "                echo \"creating online deployment\"\n",
    "                az ml online-deployment create --name $NEW_DEPLOYMENT_NAME -f Chapter09/src/deploy/model_deployment.yml -g $(resourceGroup) -w $(wsName) \n",
    "                echo \"updating online endpoint tags\"\n",
    "                az ml online-endpoint update -n $ENDPT_NAME --set tags.prod=$NEW_DEPLOYMENT_NAME  --traffic \"$NEW_DEPLOYMENT_NAME=100\" -g $(resourceGroup) -w $(wsName)\n",
    "                exit 0\n",
    "            else\n",
    "                echo \"endpoint exists, get the prod one \"\n",
    "                PROD_DEPLOYMENT=$(az ml online-endpoint show -n $ENDPT_NAME -g $(resourceGroup) -w $(wsName) -o tsv --query \"tags.prod\")\n",
    "                echo $PROD_DEPLOYMENT\n",
    "                az ml online-deployment create -g $(resourceGroup) -w $(wsName) --name $NEW_DEPLOYMENT_NAME -f Chapter09/src/deploy/model_deployment.yml \n",
    "                az ml online-endpoint update -g $(resourceGroup) -w $(wsName) -n $ENDPT_NAME --set tags.prod=$NEW_DEPLOYMENT_NAME  --traffic \"$NEW_DEPLOYMENT_NAME=100\"\n",
    "                az ml online-deployment delete -g $(resourceGroup) -w $(wsName) --endpoint $ENDPT_NAME --name $PROD_DEPLOYMENT --yes --no-wait\n",
    "            fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#az ml job create --file Chapter09/src/pipeline/aml_train_and_eval_pipeline.yml --stream --set settings.force_rerun=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./src/AzureDevOpsPipeline.yml\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ./src/AzureDevOpsPipeline.yml\n",
    "\n",
    "# resources:\n",
    "#   containers:\n",
    "#   - container: mlops\n",
    "#     image: mcr.microsoft.com/mlops/python:latest\n",
    "\n",
    "# pr: none\n",
    "# trigger:\n",
    "#   branches:\n",
    "#     include:\n",
    "#     - main\n",
    "\n",
    "# variables:\n",
    "# - group: devops-variable-group-dev\n",
    "# - group: devops-variable-group-qa\n",
    "# - name: model_name\n",
    "#   value: mmchapter9titanic\n",
    "# - name: online_endpoint_name\n",
    "#   value: chapter9titanicendpoint\n",
    "\n",
    "\n",
    "# pool:\n",
    "#   vmImage: ubuntu-latest\n",
    "\n",
    "# stages:\n",
    "# - stage: 'DevRunPipline'\n",
    "#   variables:\n",
    "#   - group: devops-variable-group-dev\n",
    "#   displayName: 'DevTrainingPipeline'\n",
    "#   jobs:\n",
    "#   - job: \"TrainingPipeline\"\n",
    "#     steps:  \n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-dev\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo \"files:\"\n",
    "#             ls\n",
    "#             az version\n",
    "#             az extension add -n ml -y\n",
    "#             az version\n",
    "#             az configure --defaults group=$(resourceGroup) workspace=$(wsName) location=$(location)\n",
    "#             az ml model list -w $(wsName) -g $(resourceGroup)  -n $(model_name) --query \"[0].version\" -o tsv\n",
    "#             echo \"##vso[task.setvariable variable=modelversion;isOutput=true]$(az ml model list -w $(wsName) -g $(resourceGroup)  -n $(model_name) --query '[0].version' -o tsv)\"\n",
    "#         name: 'setversion'\n",
    "#         displayName: 'Get Initial Model Version'\n",
    "            \n",
    "#       - task: Bash@3\n",
    "#         inputs:\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           targetType: 'inline'\n",
    "#           script: |\n",
    "#             echo 'modelversion'\n",
    "#             echo $(setversion.modelversion)     \n",
    "            \n",
    "#       - task: AzureCLI@1\n",
    "#         timeoutInMinutes: 30\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-dev\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo \"initial model version\"\n",
    "#             echo $(setversion.modelversion)\n",
    "#             echo \"files\"\n",
    "#             ls\n",
    "#             #az ml job create --file Chapter09/src/pipeline/aml_train_and_eval_pipeline.yml --stream \n",
    "#             az ml job create --file Chapter09/src/pipeline/aml_train_and_eval_pipeline.yml --stream --set settings.force_rerun=True\n",
    "#         displayName: 'Training Pipeline'\n",
    "            \n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           subscriptionId: $(subscriptionId)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-dev\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo \"files:\"\n",
    "#             ls\n",
    "#             az version\n",
    "#             az configure --defaults group=$(resourceGroup) workspace=$(wsName) location=$(location)\n",
    "#             az ml model list -w $(wsName) -g $(resourceGroup)  -n $(model_name) --query \"[0].version\" -o tsv\n",
    "#             echo \"##vso[task.setvariable variable=finalmodelversion;isOutput=true]$(az ml model list -w $(wsName) -g $(resourceGroup)  -n $(model_name) --query '[0].version' -o tsv)\"\n",
    "#             echo \"##vso[task.setvariable variable=devResourceGroup;isOutput=true]$(resourceGroup)\"\n",
    "#             echo \"##vso[task.setvariable variable=devWsName;isOutput=true]$(wsName)\"\n",
    "#             echo \"##vso[task.setvariable variable=devLocation;isOutput=true]$(location)\"\n",
    "#         name: 'setfinalversion'\n",
    "#         displayName: 'Get Final Model Version'\n",
    "            \n",
    "#       - task: Bash@3\n",
    "#         inputs:\n",
    "#           azureSubscription:\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           targetType: 'inline'\n",
    "#           script: |\n",
    "#             echo 'initial model version'$(setversion.modelversion)\n",
    "#             echo 'final model version' $(setfinalversion.finalmodelversion)\n",
    "            \n",
    "# - stage: 'QAPromoteModel'\n",
    "#   dependsOn: DevRunPipline\n",
    "#   variables:\n",
    "#   - group: devops-variable-group-qa\n",
    "#   displayName: 'QAPromoteModel'\n",
    "#   jobs:\n",
    "#   - job: \"RegisterModelQA\"\n",
    "#     variables:\n",
    "#       vardevResourceGroup: $[ stageDependencies.DevRunPipline.TrainingPipeline.outputs['setfinalversion.devResourceGroup'] ]\n",
    "#       vardevWsName: $[ stageDependencies.DevRunPipline.TrainingPipeline.outputs['setfinalversion.devWsName'] ]\n",
    "#       vardevLocation: $[ stageDependencies.DevRunPipline.TrainingPipeline.outputs['setfinalversion.devLocation'] ]\n",
    "#       vardevModelVersion: $[ stageDependencies.DevRunPipline.TrainingPipeline.outputs['setfinalversion.finalmodelversion'] ]\n",
    "#     steps:            \n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-dev\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             az extension add -n ml -y\n",
    "#             az version\n",
    "#             echo \"model version\"\n",
    "#             echo $(vardevModelVersion)\n",
    "#             az ml model list -w $(vardevWsName) -g $(vardevResourceGroup)  -n $(model_name) --query \"[0].version\" -o tsv\n",
    "#             az ml model download  -w $(vardevWsName) -g $(vardevResourceGroup)  -n $(model_name) -v $(vardevModelVersion)\n",
    "#             ls\n",
    "#         name: 'downloadmodel'\n",
    "#         displayName: 'downloadmodel'\n",
    "            \n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-qa\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo \"files:\"\n",
    "#             ls\n",
    "#             echo \"model version\" $(vardevModelVersion)\n",
    "#             az configure --defaults group=$(resourceGroup) workspace=$(wsName) location=$(location)\n",
    "#             az ml model create --name $(model_name) -v $(vardevModelVersion) --path ./$(model_name)/$(model_name) --type mlflow_model -g $(resourceGroup) -w $(wsName)\n",
    "#         name: 'registermodel'\n",
    "#         displayName: 'registermodel'\n",
    "            \n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       - task: AzureCLI@1\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-qa\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo $(checkendpointexists.result)\n",
    "#             echo $(checkendpointexists.onlinedeploymentresult)\n",
    "#             if [[ $(az ml online-endpoint show --name $(online_endpoint_name)  -g $(resourceGroup) -w $(wsName) --query provisioning_state) == 'Succeeded' ]]\n",
    "#             then\n",
    "#               echo 'already exists'\n",
    "#             else\n",
    "#               az ml online-endpoint create --file Chapter09/src/deploy/create-endpoint.yml -g $(resourceGroup) -w $(wsName)\n",
    "#             fi\n",
    "#         name: 'deployonlineendpoint'\n",
    "#         displayName: 'Online endpoint'\n",
    "            \n",
    "\n",
    "# - task: AzureCLI@1\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-qa\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo $(checkendpointexists.exists)\n",
    "#             echo $(checkendpointexists.result)\n",
    "#             if [[ $(onlinedeploymentresult) == 0 ]]\n",
    "#             then\n",
    "#             {\n",
    "#                 echo \"update model\"\n",
    "#                 az ml online-deployment update --file Chapter09/src/deploy/model_deployment.yml -g $(resourceGroup) -w $(wsName)\n",
    "#             }\n",
    "              \n",
    "#             else\n",
    "#             {\n",
    "#                 echo \"create model\"\n",
    "#                 az ml online-deployment create --file Chapter09/src/deploy/model_deployment.yml -g $(resourceGroup) -w $(wsName)\n",
    "#             }\n",
    "              \n",
    "#             fi\n",
    "#         name:'deploymodel'\n",
    "#         displayName: 'DeployModel'\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-qa\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo \"deploy end point:\"\n",
    "#             az ml online-deployment create --file Chapter09/src/deploy/model_deployment.yml -g $(resourceGroup) -w $(wsName)\n",
    "#         name: 'deploymodel'\n",
    "#         displayName: 'DeployModel'\n",
    "            \n",
    "            \n",
    "            \n",
    "# #       - task: PowerShell@2\n",
    "# #         env:\n",
    "# #           wsName: $(wsName)\n",
    "# #           resourceGroup: $(resourceGroup)\n",
    "# #           location: $(location)\n",
    "# #         inputs:\n",
    "# #           azureSubscription: aml-qa\n",
    "# #           scriptLocation: inlineScript\n",
    "# #           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "# #           targetType: 'inline' #'filePath' # 'filePath' | 'inline'. Type. Default: filePath.\n",
    "# #           script: |# string. Required when targetType = inline. Script. \n",
    "# #             ls\n",
    "# #             echo 'test'\n",
    "# #             echo \"##vso[task.setvariable variable=result;isOutput=true]$(az ml online-endpoint show --name $(online_endpoint_name)  -g $(resourceGroup) -w $(wsName) --query provisioning_state | ConvertFrom-Json)\"\n",
    "# #             echo \"##vso[task.setvariable variable=onlinedeploymentresult;isOutput=true]$(az ml online-deployment show -n green --endpoint-name $(online_endpoint_name) -g $(resourceGroup) -w $(wsName) | ConvertFrom-Json)\"\n",
    "# #             az ml online-endpoint show --name $(online_endpoint_name)  -g $(resourceGroup) -w $(wsName) --query provisioning_state | ConvertFrom-Json\n",
    "# #             echo \"deployment check\"\n",
    "# #             az ml online-deployment show -n green --endpoint-name $(online_endpoint_name) -g $(resourceGroup) -w $(wsName) | ConvertFrom-Json\n",
    "# #         name: 'checkendpointexists'\n",
    "# #         displayName: 'Get if end point exists'            \n",
    "            \n",
    "    \n",
    "# #       - task: AzureCLI@1\n",
    "# #         inputs:\n",
    "# #           azureSubscription: aml-qa\n",
    "# #           scriptLocation: inlineScript\n",
    "# #           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "# #           inlineScript: |\n",
    "# #             echo $(checkendpointexists.result)\n",
    "# #             echo $(checkendpointexists.onlinedeploymentresult)\n",
    "# #         name: 'deployonlineendpoint'\n",
    "# #         displayName: 'Online endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deploy Managed Online Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "\n",
    "# online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# # create an online endpoint\n",
    "# endpoint = ManagedOnlineEndpoint(\n",
    "#     name=online_endpoint_name,\n",
    "#     description=\"titanic online endpoint for mlflow model\",\n",
    "#     auth_mode=\"key\",\n",
    "#     tags={\"oneline endpoint\": \"titanic\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ./src/AzureDevOpsPipeline.yml\n",
    "\n",
    "# resources:\n",
    "#   containers:\n",
    "#   - container: mlops\n",
    "#     image: mcr.microsoft.com/mlops/python:latest\n",
    "\n",
    "# pr: none\n",
    "# trigger:\n",
    "#   branches:\n",
    "#     include:\n",
    "#     - main\n",
    "\n",
    "# variables:\n",
    "# - group: devops-variable-group-dev\n",
    "# - group: devops-variable-group-qa\n",
    "\n",
    "\n",
    "# pool:\n",
    "#   vmImage: ubuntu-latest\n",
    "\n",
    "# stages:\n",
    "# - stage: 'RunPipline'\n",
    "#   variables:\n",
    "#   - group: devops-variable-group-dev\n",
    "#   displayName: 'TrainingPipeline'\n",
    "#   jobs:\n",
    "#   - job: \"TrainingPipeline\"\n",
    "#     steps:\n",
    "#       - task: UsePythonVersion@0\n",
    "#         inputs:\n",
    "#           versionSpec: '3.8'\n",
    "#           addToPath: true\n",
    "#       - script: |\n",
    "#           python -m pip install --upgrade pip\n",
    "#           pip install jupyter\n",
    "#           pip install nbconvert\n",
    "#           pip install --upgrade azureml-core\n",
    "#           pip install --upgrade azureml-sdk[automl]\n",
    "      \n",
    "\n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           subscriptionId: $(subscriptionId)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-dev\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo \"files:\"\n",
    "#             ls\n",
    "#             az version\n",
    "#             az extension add -n ml -y\n",
    "#             az version\n",
    "#             az configure --defaults group=$(resourceGroup) workspace=$(wsName) location=$(location)\n",
    "#             az ml model list -w aml-dev -g aml-dev-rg  -n mmchapter8titanic --query \"[0].version\" -o tsv\n",
    "#             echo \"##vso[task.setvariable variable=modelversion;isOutput=true]$(az ml model list -w aml-dev -g aml-dev-rg  -n mmchapter8titanic --query '[0].version' -o tsv)\"\n",
    "#         name: 'setversion'\n",
    "#         displayName: 'Get Initial Model Version'\n",
    "            \n",
    "#       - task: Bash@3\n",
    "#         inputs:\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           targetType: 'inline'\n",
    "#           script: |\n",
    "#             echo 'modelversion'\n",
    "#             echo $(setversion.modelversion)     \n",
    "            \n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           subscriptionId: $(subscriptionId)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-dev\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo $initalmodelversion\n",
    "#             echo ls\n",
    "#             az ml job create --file Chapter8/src/pipeline/aml_train_and_eval_pipeline.yml --stream --set settings.force_rerun=True\n",
    "#         displayName: 'Training Pipeline'\n",
    "            \n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           wsName: $(wsName)\n",
    "#           subscriptionId: $(subscriptionId)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: aml-dev\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo \"files:\"\n",
    "#             ls\n",
    "#             az version\n",
    "#             az extension add -n ml -y\n",
    "#             az version\n",
    "#             az configure --defaults group=$(resourceGroup) workspace=$(wsName) location=$(location)\n",
    "#             az ml model list -w aml-dev -g aml-dev-rg  -n mmchapter8titanic --query \"[0].version\" -o tsv\n",
    "#             echo \"##vso[task.setvariable variable=finalmodelversion;isOutput=true]$(az ml model list -w aml-dev -g aml-dev-rg  -n mmchapter8titanic --query '[0].version' -o tsv)\"\n",
    "#         name: 'setfinalversion'\n",
    "#         displayName: 'Get Final Model Version'\n",
    "            \n",
    "#       - task: Bash@3\n",
    "#         inputs:\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           targetType: 'inline'\n",
    "#           script: |\n",
    "#             echo 'modelversion'\n",
    "#             echo $(setversion.modelversion)\n",
    "#             echo $(setfinalversion.finalmodelversion)\n",
    "            \n",
    "# - stage: 'DeployModel'\n",
    "#   dependsOn: RunPipline\n",
    "#   condition: ne(dependencies.RunPipline.outputs['TrainingPipeline.setversion.modelversion'], dependencies.RunPipline.outputs['TrainingPipeline.setversion.modelversion'])\n",
    "#   jobs:\n",
    "#   - job: \"DeployModel\"\n",
    "#     steps:\n",
    "#       - task: AzureCLI@1\n",
    "#         env:\n",
    "#           tenantId: $(tenantId)\n",
    "#           servicePrincipalId: $(servicePrincipalId)\n",
    "#           servicePrincipalPassword: $(servicePrincipalPassword)\n",
    "#           wsName: $(wsName)\n",
    "#           subscriptionId: $(subscriptionId)\n",
    "#           resourceGroup: $(resourceGroup)\n",
    "#           location: $(location)\n",
    "#         inputs:\n",
    "#           azureSubscription: dev-aml-workspace-connection\n",
    "#           scriptLocation: inlineScript\n",
    "#           workingDirectory: '$(Build.SourcesDirectory)'\n",
    "#           inlineScript: |\n",
    "#             echo \"made it:\"\n",
    "#             echo dependencies.RunPipline.outputs['TrainingPipeline.setversion.modelversion']\n",
    "#             ls\n",
    "#             az version\n",
    "#             az extension add -n ml -y\n",
    "#             az version\n",
    "#             az configure --defaults group=$(resourceGroup) workspace=$(wsName) location=$(location)\n",
    "#             az ml model list -w aml-workspace -g aml-workspace-rg  -n mmchapter8titanic --query \"[0].version\" -o tsv\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create eval.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "# import datetime\n",
    "\n",
    "# online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# # create an online endpoint\n",
    "# endpoint = ManagedOnlineEndpoint(\n",
    "#     name=online_endpoint_name,\n",
    "#     description=\"titanic online endpoint for mlflow model\",\n",
    "#     auth_mode=\"key\",\n",
    "#     tags={\"oneline endpoint\": \"titanic\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile $script_folder/endpoint.yml\n",
    "# $schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json\n",
    "# name: titanic-managed-online-endpoint\n",
    "# description: \"CLI V2 titanic online endpoint for mlflow model\"\n",
    "# auth_mode: key\n",
    "# tags : {\"CLIV2\": \"titanic\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile $script_folder/deployment.yml\n",
    "\n",
    "# $schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "# name: blue\n",
    "# endpoint_name: titanic-managed-online-endpoint\n",
    "# model: azureml:chapter6_titanic_model:1\n",
    "# code_configuration:\n",
    "#   code: \n",
    "#     local_path: .\n",
    "#   scoring_script: score.py\n",
    "# environment: azureml:job_base_env:1\n",
    "# instance_type: Standard_F2s_v2\n",
    "# instance_count: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile $script_folder/score.py\n",
    "\n",
    "# import os \n",
    "# import json\n",
    "# import joblib\n",
    "# from pandas import json_normalize\n",
    "# import pandas as pd\n",
    "\n",
    "# # Called when the service is loaded\n",
    "# def init():\n",
    "#     global model\n",
    "#     # Get the path to the deployed model file and load it\n",
    "#     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'titanic_model.pkl')\n",
    "#     model = joblib.load(model_path)\n",
    "\n",
    "# # Called when a request is received\n",
    "# def run(raw_data):\n",
    "#     dict= json.loads(raw_data)\n",
    "#     df = json_normalize(dict['raw_data']) \n",
    "#     y_pred = model.predict(df)\n",
    "#     print(type(y_pred))\n",
    "    \n",
    "#     result = {\"result\": y_pred.tolist()}\n",
    "#     return result"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
