{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Hyperparameter Tuning\n",
    "\n",
    "## In this notebook we will:\n",
    "\n",
    "  - Connect to your workspace.\n",
    "  - Create a virtual environment and leverage in this notebook\n",
    "  - Explore the dataset\n",
    "  - Data cleansing and analysis work\n",
    "  - Feature Engineering\n",
    "  - Register the cleansed data\n",
    "  - Explore leveraging an MLTable\n",
    "  - Run a job that leverages\n",
    "    - sklearn pipeline for data transformation\n",
    "    - `mlflow.autolog` for capturing *training* and *test* metrics\n",
    "    - log additional metrics to a given job run\n",
    "  - download and use a model that is created as a result of the job\n",
    "  - Use `Sweep` to search for the best hyperparamers for a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting yourself up for success\n",
    "\n",
    "- When creating a model, one of the major obstacles is having an environment that has the required dependencies.  We will create and register an AML environment and use on our compute instance.  This will allow us to leverage the model we build on a compute cluster on our compute instance.  The same packages and versions leveraged to build the model will be used to consume the model later in this notebook\n",
    "\n",
    "Steps to setup our environment include:\n",
    "- Connecting to our workspace\n",
    "- Defining and registering the environment\n",
    "- Making the environment available to our compute instance \n",
    "- Making the environment available to our jupyter notebook\n",
    "\n",
    "Let's get started\n",
    "\n",
    "Select **Kernel** > **Change Kernel** > **Python 3.10 - SDK V2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.ai.ml\n",
    "print(azure.ai.ml._version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml.entities import Environment, BuildContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to your workspace\n",
    "\n",
    "Once you connect to your workspace, you will create a new cpu target which you will provide an environment to.\n",
    "\n",
    "- We should be able to connect with the MLClient using your credentials in the config of the compute instance.  You should not keep your subscription id, resource group or workspace name visible in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = ''\n",
    "resource_group = ''\n",
    "workspace = ''\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup enviroment\n",
    "\n",
    "### Creating environment from docker image with a conda YAML\n",
    "\n",
    "Azure ML allows you to leverage curated environments, as well as to build your own environment from:\n",
    "\n",
    "    - existing docker image\n",
    "    - base docker image with a conda yml file to customize\n",
    "    - a docker build content\n",
    "    \n",
    "We will proceed with creating an environment from a docker build plus a conda yml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"conda-yamls\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create job environment in a yml file\n",
    "\n",
    "- At the time of writing this, the versions of `mlflow`, `azure-ai-ml` `mltable` and `azureml-mlflow` where set accordingly below.  They have been set to ensure stability of the notebook, but please update them according to the lastest package versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conda-yamls/job_env.yml\n",
    "name: job_env\n",
    "dependencies:\n",
    "- python=3.10\n",
    "- scikit-learn=1.1.3\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - mlflow==2.0.1\n",
    "  - azure-ai-ml==1.1.2\n",
    "  - mltable==1.0.0\n",
    "  - azureml-mlflow==1.48.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the most current and up-to-date base image\n",
    "\n",
    "Default images are always changing.  \n",
    "Note the base image is defined in the property `image` below.  These images are defined at [https://hub.docker.com/_/microsoft-azureml](https://hub.docker.com/_/microsoft-azureml)\n",
    "\n",
    "The current image we have selected for this notebook is `mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04`, but based on image availability, that will change in the future.  In additon, note the python version specified in your conda environment file is `python=3.10`, as this will evolve over time as well.  Currently `MLTable` is not available in python 3.10, but as that changes, we encourage you to update python version as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    conda_file=\"conda-yamls/job_env.yml\",\n",
    "    name=\"job_base_env\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use your virtual environment in this notebook\n",
    "\n",
    "We can actually use that virtual environment on our compute instance and in this very jupyter notebook.\n",
    "Open a terminal session, and cd into your conda-yamls folder and run the following commands:\n",
    "\n",
    "```\n",
    "cd ML-Engineering-with-Azure-Machine-Learning-Service/\n",
    "cd 'chapter 4'\n",
    "cd conda-yamls/\n",
    "conda env create -f job_env.yml\n",
    "conda activate job_env\n",
    "ipython kernel install --user --name job_env --display-name \"job_env\"\n",
    "```\n",
    "* After the environment has been made available to Jupyter, Refresh this session (F5, or Hit refresh on your browser)\n",
    "\n",
    "When you go to your `Kernel` -> `Change Kernel`, it will be available to select.  You will have to rerun the notebook, but when you download the model, you will be using all of the correct versions of libraries.\n",
    "\n",
    "*Note to remove an environment with conda leverage \n",
    "```\n",
    "conda env remove -n job_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset\n",
    "\n",
    "You're going to use a Python script to train a machine learning model based on the Titanic datset found in your data folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./data/titanic.csv')\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset field information\n",
    "\n",
    "- **PassengerId**: (remove) Should be removed from model as they are some sort of id.\n",
    "- **Pclass**: (keep) locates folks on ship *Pclass: 1st = Upper, 2nd = Middle, 3rd = Lower*\n",
    "- **Name**: (remove) maybe found useful if keeping the surname, but for basic model will remove\n",
    "- **Sex**: (keep) due to lifeboat priority, will likely be useful\n",
    "- **Age**: (keep)important due to lifeboat priority\n",
    "- **SibSp**: (keep) maybe useful, relatives will likely help others\n",
    "- **Parch**: (keep) maybe useful, relatives will likely help others\n",
    "- **Ticket**: (remove)\n",
    "- **Fare**: (remove covered by class)\n",
    "- **Cabin**: (keep) can be useful in relation of where the cabins are positioned on the ship\n",
    "- **Embarked**: (keep) useful because all listed embark happened before the disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering\n",
    "\n",
    "## Data Cleansing\n",
    "\n",
    "We will begin by evaluating the null values in the dataset.  Note that Age, Fare and Cabin contain null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns_missing = df.isna().sum().where(lambda x : x > 0).dropna()\n",
    "\n",
    "ax = columns_missing \\\n",
    ".plot(kind='bar', alpha=0.9, title='Columns Missing Values', table=True)\n",
    "ax.xaxis.set_visible(False) # hide x axis labels\n",
    "\n",
    "for x in ax.patches:\n",
    "    ax.text(x.get_x()+.1, x.get_height()+5, \\\n",
    "            str(round((x.get_height()/df.shape[0])*100, 1))+'%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for an experiment\n",
    "In the previous notebook, the data was leveraged directly from the folder on the compute instance.  We will be submitting an experiment to a compute cluster, so we will register the dataset so it will be stored in the blob storage associated with the AML workspace\n",
    "\n",
    "### Stategy:\n",
    "\n",
    "- For the Age, we will replace the missing values with the medians of each group\n",
    "- For cabin we will mark it as X given this is probably an important feature that we would want to include.\n",
    "- For Embarked,given there are only 2 rows missing this value, we will set these to a value of S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Age Column\n",
    "\n",
    "Note that Age, a column that has missing data, will likely be impacted by class, as people are more established,their age will likely increase, so to replace these values, we will group by class and sex, calculate a median value and replace the na values in the dataset with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.groupby(['Pclass', 'Sex'])['Age'].count())\n",
    "\n",
    "display(df.groupby(['Pclass', 'Sex'])['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df.groupby(['Pclass', 'Sex'],group_keys=False)['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Sex'].unique())\n",
    "df['Sex']= df['Sex'].apply(lambda x: x[0] if pd.notnull(x) else 'X')\n",
    "print(df['Sex'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Loc']= df['Cabin'].apply(lambda x: x[0] if pd.notnull(x) else 'X')\n",
    "df[['Loc', 'Survived']].groupby('Loc')['Survived'].mean().plot(kind= 'bar')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Cabin', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'] = df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Create a Group Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'GroupSize'] = 1 + df['SibSp'] + df['Parch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Embarded with value of S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'Survived'\n",
    "columns_to_keep = ['Pclass', 'Sex','Age', 'Fare', 'Embared', 'Deck', 'GroupSize']\n",
    "columns_to_drop = ['Name','SibSp', 'Parch', 'Survived']\n",
    "df_train = df\n",
    "df = df_train.drop(['Name','SibSp', 'Parch', 'PassengerId'], axis=1)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"prepped_data\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "df.to_csv('./prepped_data/titanic_prepped.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Data\n",
    "\n",
    "Data can reside in:\n",
    "\n",
    "    - Local Machine: URI_FILE, URI_FOLDER, MLTABLE, TRITON_MODEL, CUSTOM_MODEL\n",
    "    - Web\n",
    "    - Data Storage Services (Bob, ADSL, SQL)\n",
    "        - https://<account_name>.blob.core.windows.net/<container_name>/path\n",
    "        - abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>\n",
    "        - azureml://datastores/<data_store_name>/paths/<path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can register the a csv file directly from the data directory, we are using a csv file in the directory, but you can leverage data from supported cloud storage using `https`, `abfss` and `wasbs` \n",
    "\n",
    "### Register a uri_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    registered_data_asset = ml_client.data.get(name='titanic_prepped', version=1)\n",
    "    print('data asset is registered')\n",
    "except:\n",
    "    print('register data asset')\n",
    "    my_data = Data(\n",
    "        path=\"./prepped_data/titanic_prepped.csv\",\n",
    "        type=AssetTypes.URI_FILE,\n",
    "        description=\"Titanic CSV\",\n",
    "        name=\"titanic_prepped\",\n",
    "        version=\"1\",\n",
    "    )\n",
    "\n",
    "    ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with an MLTable\n",
    "\n",
    "`MLTable` are great for:\n",
    "- when your data is complex\n",
    "- you only need a subset of the data\n",
    "- you will leverage dataset with **AutoML** job which requires tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"titanic_prepped_mltable\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MLTable Definition file\n",
    "Note we can exclude columns right in the definition based on the MLTable.schema.json definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile titanic_prepped_mltable/MLTable\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/MLTable.schema.json \n",
    "\n",
    "type: mltable\n",
    "paths:\n",
    "    - pattern: ./*.csv\n",
    "\n",
    "transformations:\n",
    "  - read_delimited:\n",
    "      delimiter: \",\"\n",
    "      header: all_files_same_headers\n",
    "      encoding: utf8\n",
    "  - drop_columns: [\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "data_file = './prepped_data/titanic_prepped.csv'\n",
    "target   = script_folder + '/titanic_prepped.csv'\n",
    "shutil.copyfile(data_file, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an MLTable before registration\n",
    "\n",
    "You should located the `MLTable` file with the data.  You can load an `MLTable` using the `mltable` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltable\n",
    "\n",
    "# Note: the uri below can be a local folder or folder located in cloud storage. The folder must contain a valid MLTable file.\n",
    "script_folder = os.path.join(os.getcwd(), \"titanic_prepped_mltable\")\n",
    "print(script_folder)\n",
    "tbl = mltable.load(uri=script_folder)\n",
    "tbl.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register an MLTable\n",
    "\n",
    "an MLTable can be leveraged as an input to a job or pipeline.  \n",
    "After it is registered, you can also retrieve it by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    registered_data_asset = ml_client.data.get(name='titanic_prepped_mltable_x2', version=1)\n",
    "    print('retrieved registered data asset')\n",
    "except:\n",
    "    print('registering ml table')\n",
    "    titanic_data = Data(\n",
    "        name=\"titanic_prepped_mltable_x2\",\n",
    "        path='./titanic_prepped_mltable/',\n",
    "        type=AssetTypes.MLTABLE,\n",
    "        description=\"Dataset for titanic\",\n",
    "        tags={\"source_type\": \"file\", \"source\": \"ML Engineering\"},\n",
    "        version=\"1\",\n",
    "    )\n",
    "    titanic_data = ml_client.data.create_or_update(titanic_data)\n",
    "    print(f\"Dataset with name {titanic_data.name} was registered to workspace, the dataset version is {titanic_data.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_v1_data_asset = ml_client.data.get(name='titanic_prepped_mltable_x2', version='1')\n",
    "print(registered_v1_data_asset.path)\n",
    "\n",
    "tbl = mltable.load(uri=registered_v1_data_asset.path)\n",
    "tbl.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Compute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# specify aml compute name.\n",
    "cpu_compute_target = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    ml_client.compute.get(cpu_compute_target)\n",
    "except Exception:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "    compute = AmlCompute(\n",
    "        name=cpu_compute_target, size=\"STANDARD_D2_V2\", min_instances=0, max_instances=4, idle_time_before_scale_down = 1800\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating code to generate Basic Model\n",
    "\n",
    "We will first create a model using the job command, and then leverage the `jobsweep` command with specified parameters for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = os.path.join(os.getcwd(), \"src\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create main.py file for running in your command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./src/main.py\n",
    "import os\n",
    "import argparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# define functions\n",
    "def main(args):\n",
    "    current_run = mlflow.start_run()\n",
    "    mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "    # read in data\n",
    "    df = pd.read_csv(args.titanic_csv)\n",
    "    model = model_train('Survived', df, args.randomstate)\n",
    "    mlflow.end_run()\n",
    "\n",
    "def model_train(LABEL, df, randomstate):\n",
    "    print('df.columns = ')\n",
    "    print(df.columns)\n",
    "    \n",
    "    df['Embarked'] = df['Embarked'].astype(object)\n",
    "    df['Loc'] = df['Loc'].astype(object)\n",
    "    df['Loc'] = df['Sex'].astype(object)\n",
    "    df['Pclass'] = df['Pclass'].astype(float)\n",
    "    df['Age'] = df['Age'].astype(float)\n",
    "    df['Fare'] = df['Fare'].astype(float)\n",
    "    df['GroupSize'] = df['GroupSize'].astype(float)\n",
    "\n",
    "    y_raw           = df[LABEL]\n",
    "    columns_to_keep = ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "    X_raw           = df[columns_to_keep]\n",
    "\n",
    "    print(X_raw.columns)\n",
    "     # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=randomstate)\n",
    "    \n",
    "    #use Logistic Regression estimator from scikit learn\n",
    "    lg = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    preprocessor = buildpreprocessorpipeline(X_train)\n",
    "    \n",
    "    #estimator instance\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', lg)], verbose=True)\n",
    "\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    \n",
    "    print('type of X_test = ' + str(type(X_test)))\n",
    "          \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print('*****X_test************')\n",
    "    print(X_test)\n",
    "    \n",
    "    #get the active run.\n",
    "    run = mlflow.active_run()\n",
    "    print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "\n",
    "    acc = model.score(X_test, y_test )\n",
    "    print('Accuracy:', acc)\n",
    "    MlflowClient().log_metric(run.info.run_id, \"test_acc\", acc)\n",
    "    \n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "    print('AUC: ' , auc)\n",
    "    MlflowClient().log_metric(run.info.run_id, \"test_auc\", auc)\n",
    "    \n",
    "    \n",
    "    # Signature\n",
    "    signature = infer_signature(X_test, y_test)\n",
    "\n",
    "    # Conda environment\n",
    "    custom_env =_mlflow_conda_env(\n",
    "        additional_conda_deps=[\"scikit-learn==1.1.3\"],\n",
    "        additional_pip_deps=[\"mlflow<=1.30.0\"],\n",
    "        additional_conda_channels=None,\n",
    "    )\n",
    "\n",
    "    # Sample\n",
    "    input_example = X_train.sample(n=1)\n",
    "\n",
    "    # Log the model manually\n",
    "    mlflow.sklearn.log_model(model, \n",
    "                             artifact_path=\"model\", \n",
    "                             conda_env=custom_env,\n",
    "                             signature=signature,\n",
    "                             input_example=input_example)\n",
    "\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def buildpreprocessorpipeline(X_raw):\n",
    "\n",
    "    categorical_features = X_raw.select_dtypes(include=['object', 'bool']).columns\n",
    "    numeric_features = X_raw.select_dtypes(include=['float','int64']).columns\n",
    "\n",
    "    #categorical_features = ['Sex', 'Embarked', 'Loc']\n",
    "    categorical_transformer = Pipeline(steps=[('onehotencoder', \n",
    "                                               OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "    #numeric_features = ['Pclass', 'Age', 'Fare', 'GroupSize']    \n",
    "    numeric_transformer1 = Pipeline(steps=[('scaler1', SimpleImputer(missing_values=np.nan, strategy = 'mean'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric1', numeric_transformer1, numeric_features),\n",
    "            ('categorical', categorical_transformer, categorical_features)], remainder='drop')\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--titanic-csv\", type=str)\n",
    "    parser.add_argument(\"--randomstate\", type=int, default=42)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Command\n",
    "\n",
    "- `display_name` display name for the job\n",
    "- `description`  the description of the experiment\n",
    "- `code` path where the code is located\n",
    "- `command` command to run\n",
    "- `inputs`  dictionary of name value pairs using `${{inputs.<input_name>}}`\n",
    "    \n",
    "    - To use files or folder - using the `Input` class\n",
    "        \n",
    "        - `type` defaults to a `uri_folder` but this can be set to `uri_file` or `uri_folder`\n",
    "        - `path` is the path to the file or folder.  These can be local or remote leveraging **https, http, wasb`\n",
    "        \n",
    "            - To use an Azure ML dataset, this would be an Input `Input(type='uri_folder', path='my_dataset:1')`\n",
    "            \n",
    "            - `mode` is how the data should be delivered to the compute which include `ro_mount`(default), `rw_mount` and `download`\n",
    "\n",
    "- `environment`: environment to be used by compute when running command\n",
    "- `compute`: can be `local`, or a specificed compute name\n",
    "- `distribution`: distribution to leverage for distributed training scenerios including:\n",
    "        \n",
    "    - `Pytorch`\n",
    "    - `TensorFlow`\n",
    "    - `MPI`\n",
    "            \n",
    "            \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the command\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "my_job = command(\n",
    "    code=\"./src\",  # local path where the code is stored\n",
    "    command=\"python main.py --titanic ${{inputs.titanic}} --randomstate ${{inputs.randomstate}}\",\n",
    "    inputs={\n",
    "        \"titanic\": Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"azureml:titanic_prepped:1\",\n",
    "        ),\n",
    "        \"randomstate\": 0,\n",
    "    },\n",
    "    environment=\"job_base_env@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    display_name=\"sklearn-titanic\",\n",
    "    # description,\n",
    "    # experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = os.path.join(os.getcwd(), \"job\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Command with SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the command\n",
    "returned_job = ml_client.create_or_update(my_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = returned_job.name\n",
    "print('run_id:' + run_id)\n",
    "experiment = returned_job.experiment_name\n",
    "print(\"experiment:\" + experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always get the list of runs using ml flow.  Below we will track our process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import time\n",
    "\n",
    "exp = mlflow.get_experiment_by_name(experiment)\n",
    "last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
    "\n",
    "if last_run.info.run_id != run_id:\n",
    "    print('run ids were not the same - waiting for run id to update')\n",
    "    time.sleep(5)\n",
    "    exp = mlflow.get_experiment_by_name(experiment)\n",
    "    last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
    "\n",
    "while last_run.info.status == 'SCHEDULED':\n",
    "  print('run is being scheduled')\n",
    "  time.sleep(5)\n",
    "  last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
    "\n",
    "while last_run.info.status == 'RUNNING':\n",
    "  print('job is being run')\n",
    "  time.sleep(10)\n",
    "  last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
    "\n",
    "print(\"run_id:{}\".format(last_run.info.run_id))\n",
    "print('----------')\n",
    "print(\"run_id:{}\".format(last_run.info.status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a job.yml file\n",
    "\n",
    "Note you can also run a command through the CLI.  This is great preperation for MLOps. The file below will allow use to leverage the AML CLI V2 to run this command.  We can and will run it through the CLI, but it is included here for completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./job/job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "code: ../src\n",
    "command: >-\n",
    "  python main.py \n",
    "  --titanic-csv ${{inputs.titanic}}\n",
    "  --randomstate ${{inputs.randomstate}}\n",
    "inputs:\n",
    "  titanic:\n",
    "    path: azureml:titanic_prepped:1\n",
    "    mode: ro_mount\n",
    "  randomstate: 0   \n",
    "environment: azureml:job_base_env@latest\n",
    "compute: azureml:cpu-cluster\n",
    "experiment_name: titanic-job-example\n",
    "description: | \n",
    "    # Train a classification model on diabetes data using a registered dataset as input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the CLI to run this command now that you have created a yml file.  Navigate on your compute instace to the folder holding the job.yml file and run the following command in the terminal.\n",
    "\n",
    "* Note to replace the workspace name in the command with your workspace name (update the value: aml-workspace), and the resource group (update the value: aml-workspace-rg) with your resource group name\n",
    "\n",
    "```\n",
    "az login\n",
    "az ml job create --file job.yml --web --resource-group aml-workspace-rg --workspace-name aml-workspace\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all of the artifacts that were automatically logged as part of your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "print(experiment)\n",
    "print(run_id)\n",
    "mlflow.set_experiment(experiment_name=experiment)\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.list_artifacts(run_id=run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download any artifact from the list of artifacts - and display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = client.download_artifacts(\n",
    "    run_id, path=\"training_confusion_matrix.png\"\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "image = img.imread(file_path)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Model and consume locally\n",
    "\n",
    "Given the model was already logged as a job artifact, we can download it locally and run it.  \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(last_run.info.run_id)\n",
    "pipeline_model = mlflow.sklearn.load_model(f\"runs:/{last_run.info.run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pipeline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = os.path.join(os.getcwd(), \"titanic_prepped_mltable\")\n",
    "print(script_folder)\n",
    "tbl = mltable.load(uri=script_folder)\n",
    "df  = tbl.to_pandas_dataframe()\n",
    "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "X_raw           = df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipeline_model.predict(X_raw)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Model \n",
    "\n",
    "Using the Python SDK V2 - we can register the Model for use.  \n",
    "\n",
    "Parameters for model registration include:\n",
    "\n",
    "- `path` - A remote uri or local path pointing at the model\n",
    "- `name` - A string value\n",
    "- `description` - A description for the model\n",
    "- `type` - valid values include: \n",
    "    - \"custom_model\"\n",
    "    - \"mlflow_model\" \n",
    "    - \"triton_model\".  \n",
    "    \n",
    "* Instead of typing out the `type`, you can use the AssetTypes in the namespace azure.ai.ml.constants as we have done below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "run_model = Model(\n",
    "    path=f\"runs:/{last_run.info.run_id}/model\",\n",
    "    name=\"titanic_model\",\n",
    "    description=\"Model created from run.\",\n",
    "    type=AssetTypes.MLFLOW_MODEL \n",
    ")\n",
    "\n",
    "ml_client.models.create_or_update(run_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Sweep\n",
    "\n",
    "Configure your experiment to tune your hyperparameters.  The parameters can be discrete or continuous values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep Function\n",
    "The Sweep Function allows you to define:\n",
    "\n",
    "  - for the job `sampling_algorithm` to be \n",
    "    - random\n",
    "    - grid\n",
    "    - bayesian\n",
    "  - `objective`: \n",
    "    - primary_metric - the metric must be loggin the the training script using mflow.log_metric()\n",
    "    - goal - the optimzation goal of the objective.primary_metric\n",
    "      - maximize\n",
    "      - minimize\n",
    "  - `compute` - name of the compute target to excute the job on\n",
    "  - `limits` - limits for the sweep job\n",
    "\n",
    "The **Best Child Run** on the Overview screen will show you the best performing child run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Script to take hyperparameters\n",
    "\n",
    "We will update the script a bit, and now take in hyperparameters.\n",
    "\n",
    "```\n",
    "parser.add_argument(\"--penalty-term\", type=str, default='l1')\n",
    "parser.add_argument(\"--C\", type=float, default=0.01)\n",
    "parser.add_argument(\"--max-iter\", type=int, default=100)\n",
    "```\n",
    "\n",
    "We have also updated the script to include additional logging so you can gain familiarity with mlflow logging if you are not already familiar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"hyperparametertune\")\n",
    "print(script_folder)\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./hyperparametertune/main.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# define functions\n",
    "def main(args):\n",
    "    # enable auto logging\n",
    "    current_run = mlflow.start_run()\n",
    "    mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "    # read in data\n",
    "    df = pd.read_csv(args.titanic_csv)\n",
    "    model = model_train('Survived', df, args.penalty_term, args.C, args.max_iter, args.randomstate)\n",
    "    mlflow.end_run()\n",
    "\n",
    "def fetch_logged_data(run_id):\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    data = client.get_run(run_id).data\n",
    "    tags = {k: v for k, v in data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in client.list_artifacts(run_id, \"model\")]\n",
    "    return data.params, data.metrics, tags, artifacts\n",
    "\n",
    "def model_train(LABEL, df, penalty_term, C, max_iter, randomstate):\n",
    "    print('df.columns = ')\n",
    "    print(df.columns)\n",
    "    \n",
    "    df['Embarked'] = df['Embarked'].astype(object)\n",
    "    df['Loc'] = df['Loc'].astype(object)\n",
    "    df['Loc'] = df['Sex'].astype(object)\n",
    "    df['Pclass'] = df['Pclass'].astype(float)\n",
    "    df['Age'] = df['Age'].astype(float)\n",
    "    df['Fare'] = df['Fare'].astype(float)\n",
    "    df['GroupSize'] = df['GroupSize'].astype(float)\n",
    "\n",
    "    y_raw           = df[LABEL]\n",
    "    columns_to_keep = ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "    X_raw           = df[columns_to_keep]\n",
    "    \n",
    "    print(X_raw.columns)\n",
    "     # Train test split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, shuffle=randomstate)\n",
    "    \n",
    "    #use Logistic Regression estimator from scikit learn\n",
    "    \n",
    "    lg = LogisticRegression(penalty=penalty_term, C=C, max_iter=max_iter, solver='liblinear')\n",
    "    preprocessor = buildpreprocessorpipeline(X_train)\n",
    "    \n",
    "    #estimator instance\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', lg)], verbose=True)\n",
    "\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    #get the active run.\n",
    "    run = mlflow.active_run()\n",
    "    print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "    \n",
    "\n",
    "    acc = model.score(X_test, y_test )\n",
    "    print('Accuracy:', acc)\n",
    "    MlflowClient().log_metric(run.info.run_id, \"test_ACC\", acc)\n",
    "    \n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "    print('AUC: ' , auc)\n",
    "    MlflowClient().log_metric(run.info.run_id, \"test_AUC\", auc)\n",
    "    \n",
    "    params, metrics, tags, artifacts = fetch_logged_data(run.info.run_id)\n",
    "    \n",
    "    print('******************************')\n",
    "    print(params)\n",
    "    print('******************************')\n",
    "    print(metrics)\n",
    "    print('******************************')\n",
    "    \n",
    "    # Signature\n",
    "    signature = infer_signature(X_test, y_test)\n",
    "\n",
    "    # Conda environment\n",
    "    custom_env =_mlflow_conda_env(\n",
    "        additional_conda_deps=[\"scikit-learn==1.1.3\"],\n",
    "        additional_pip_deps=[\"mlflow<=1.30.0\"],\n",
    "        additional_conda_channels=None,\n",
    "    )\n",
    "\n",
    "    # Sample\n",
    "    input_example = X_train.sample(n=1)\n",
    "\n",
    "    # Log the model manually\n",
    "    mlflow.sklearn.log_model(model, \n",
    "                             artifact_path=\"model\", \n",
    "                             conda_env=custom_env,\n",
    "                             signature=signature,\n",
    "                             input_example=input_example)\n",
    "\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def buildpreprocessorpipeline(X_raw):\n",
    "\n",
    "    categorical_features = X_raw.select_dtypes(include=['object', 'bool']).columns\n",
    "    numeric_features = X_raw.select_dtypes(include=['float','int64']).columns\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=\"missing\")),\n",
    "                                              ('onehotencoder', OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore'))])\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_features),\n",
    "            ('categorical', categorical_transformer, categorical_features)\n",
    "        ], remainder=\"passthrough\")\n",
    "    \n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--titanic-csv\", type=str)\n",
    "    parser.add_argument(\"--penalty-term\", type=str, default='l1')\n",
    "    parser.add_argument(\"--C\", type=float, default=0.01)\n",
    "    parser.add_argument(\"--max-iter\", type=int, default=100)\n",
    "    parser.add_argument(\"--randomstate\", type=int, default=42)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy, BanditPolicy, TruncationSelectionPolicy\n",
    "\n",
    "grid_sampling_job_command = command(\n",
    "    code=\"./hyperparametertune\",  # local path where the code is stored\n",
    "    command=\"python main.py --titanic ${{inputs.titanic}} --randomstate ${{inputs.randomstate}}\",\n",
    "    inputs={\n",
    "        \"titanic\": Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"azureml:titanic_prepped:1\",\n",
    "        ),\n",
    "        \"randomstate\": 0,\n",
    "        \"penalty_term\": 'l1',\n",
    "        \"C\": 0.01,\n",
    "        \"max_iter\": 100,\n",
    "    },\n",
    "    environment=\"job_base_env@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    display_name=\"GridSampling\",\n",
    ")\n",
    "\n",
    "#Set Parameter expressions\n",
    "grid_command_job_for_sweep = grid_sampling_job_command(\n",
    "    penalty_term=Choice(values=['l2', 'l1']),\n",
    "    C=Choice(values=[0.01, .1, 1.0, 10]),\n",
    "    max_iter=Choice(values=[10, 100, 150, 200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "grid_sweep_job = grid_command_job_for_sweep.sweep(\n",
    "    compute=\"cpu-cluster\",\n",
    "    sampling_algorithm=\"grid\",\n",
    "    primary_metric=\"test_AUC\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "#2*4*4 = 32 trial runs, but we will explicity set the max total trials, to see it is not exceeded\n",
    "grid_sweep_job.set_limits(max_total_trials=60, \n",
    "                     max_concurrent_trials=10, \n",
    "                     timeout=7200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(grid_sweep_job)\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_sweep_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = returned_sweep_job.name\n",
    "print('run_id:' + run_id)\n",
    "experiment = returned_job.experiment_name\n",
    "print(\"experiment:\" + experiment)\n",
    "\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_status(experiment_id, run_id):\n",
    "    df = mlflow.search_runs([experiment_id])\n",
    "    rslt_df = df[(df['tags.mlflow.parentRunId'] == run_id )]\n",
    "    rslt_df_finished = rslt_df[rslt_df['status'] == 'FINISHED']\n",
    "\n",
    "    while rslt_df.shape[0] == 0:\n",
    "        print('waiting for jobs to register')\n",
    "        df = mlflow.search_runs([experiment_id])\n",
    "        rslt_df = df[(df['tags.mlflow.parentRunId'] == run_id )]\n",
    "        rslt_df_finished = rslt_df[rslt_df['status'] == 'FINISHED']\n",
    "        time.sleep(5)\n",
    "\n",
    "    while rslt_df_finished.shape[0] != rslt_df.shape[0]:\n",
    "        df = mlflow.search_runs([experiment_id])\n",
    "        rslt_df = df[(df['tags.mlflow.parentRunId'] == run_id )]\n",
    "        rslt_df_finished = rslt_df[rslt_df['status'] == 'FINISHED']\n",
    "        status = rslt_df[\"status\"].unique()\n",
    "        print(status)\n",
    "        for x in status:\n",
    "            rslt_df_status = rslt_df[rslt_df['status'] == x]\n",
    "            print(returned_sweep_job.display_name + ', Number:' + str(x) + \" \" +  str(rslt_df_status.shape[0]))\n",
    "        time.sleep(5)\n",
    "\n",
    "    print('Sweep Job for run:' + run_id + ' Complete')\n",
    "    \n",
    "get_job_status(experiment_id, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling\n",
    "\n",
    "- Random sampling supports leveraging continuous and discrete hyperparameters.  \n",
    "- Hyperparameters are selected randomly from the defined search space.  \n",
    "- Note below we define the following hyperparameters:\n",
    "    - **penalty_term** to be either 'l1' or 'l2'\n",
    "    - **C** which is a value from 0.01-10.0\n",
    "    - **max_iter** is a choice of either 10, 100, 150 or 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy, BanditPolicy, TruncationSelectionPolicy\n",
    "\n",
    "random_sampling_job_command = command(\n",
    "    code=\"./hyperparametertune\",  # local path where the code is stored\n",
    "    command=\"python main.py --titanic ${{inputs.titanic}} --randomstate ${{inputs.randomstate}}\",\n",
    "    inputs={\n",
    "        \"titanic\": Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"azureml:titanic_prepped:1\",\n",
    "        ),\n",
    "        \"randomstate\": 0,\n",
    "        \"penalty_term\": 'l1',\n",
    "        \"C\": 0.01,\n",
    "        \"max_iter\": 100,\n",
    "    },\n",
    "    environment=\"job_base_env@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    display_name=\"RandomSampling\",\n",
    ")\n",
    "\n",
    "# #Set Parameter expressions\n",
    "# #choice, randint, qlognormal, qnormal, qloguniform, quniform, lognormal, normal, loguniform, uniform\n",
    "random_command_job_for_sweep = random_sampling_job_command(\n",
    "    penalty_term=Choice(values=['l2', 'l1']),\n",
    "    C=Uniform(min_value=0.01, max_value=10.0),\n",
    "    max_iter=Choice(values=[10, 100, 150, 200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "random_sweep_job = random_command_job_for_sweep.sweep(\n",
    "    compute=\"cpu-cluster\",\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"test_AUC\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "random_sweep_job.set_limits(max_total_trials=120, \n",
    "                     max_concurrent_trials=10, \n",
    "                     timeout=7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(random_sweep_job)\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_sweep_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = returned_sweep_job.name\n",
    "print('run_id:' + run_id)\n",
    "experiment = returned_job.experiment_name\n",
    "print(\"experiment:\" + experiment)\n",
    "\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_job_status(experiment_id, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling with Truncation Policy\n",
    "\n",
    "- As previous we will leverage the random sampling, but now we will apply a truncation policy.\n",
    "- The truncation selection cancels a percent of the worst performing jobs at each interval based on the selected primary metric.\n",
    "\n",
    "- Random sampling supports leveraging continuous and discrete hyperparameters.  \n",
    "- Hyperparameters are selected randomly from the defined search space.  \n",
    "- Note below we define the following hyperparameters:\n",
    "    - **penalty_term** to be either 'l1' or 'l2'\n",
    "    - **C** which is a value from 0.01-10.0\n",
    "    - **max_iter** is a choice of either 10, 100, 150 or 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy, BanditPolicy, TruncationSelectionPolicy\n",
    "\n",
    "\n",
    "rnd_sample_trun_command = command(\n",
    "    code=\"./hyperparametertune\",  # local path where the code is stored\n",
    "    command=\"python main.py --titanic ${{inputs.titanic}} --randomstate ${{inputs.randomstate}}\",\n",
    "    inputs={\n",
    "        \"titanic\": Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"azureml:titanic_prepped:1\",\n",
    "        ),\n",
    "        \"randomstate\": 0,\n",
    "        \"penalty_term\": 'l1',\n",
    "        \"C\": 0.01,\n",
    "        \"max_iter\": 100,\n",
    "    },\n",
    "    environment=\"job_base_env@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    display_name=\"RandomSamplingwTruncationPolicy\",\n",
    ")\n",
    "\n",
    "# #Set Parameter expressions\n",
    "# #choice, randint, qlognormal, qnormal, qloguniform, quniform, lognormal, normal, loguniform, uniform\n",
    "rnd_sample_trun_job_for_sweep = rnd_sample_trun_command(\n",
    "    penalty_term=Choice(values=['l2', 'l1']),\n",
    "    C=Uniform(min_value=0.01, max_value=10.0),\n",
    "    max_iter=Choice(values=[10, 100, 150, 200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "sweep_job = rnd_sample_trun_job_for_sweep.sweep(\n",
    "    compute=\"cpu-cluster\",\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"training_roc_auc_score\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "sweep_job.set_limits(max_total_trials=120, \n",
    "                     max_concurrent_trials=10, \n",
    "                     timeout=7200)\n",
    "\n",
    "#early_termination - Early termination policy to end poorly performing runs. If no termination policy is specified, all configurations are run to completion. \n",
    "sweep_job.early_termination = TruncationSelectionPolicy(evaluation_interval= 1, truncation_percentage= 75, delay_evaluation= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_sweep_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = returned_sweep_job.name\n",
    "print('run_id:' + run_id)\n",
    "experiment = returned_job.experiment_name\n",
    "print(\"experiment:\" + experiment)\n",
    "\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Status leveraging MLFlow Capabilites\n",
    "\n",
    "Using MLFlow, we can get back a dataframe that includes all of the trials for a given Sweep Job Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_job_status(experiment_id, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling with Median Early Termination Policy\n",
    "\n",
    "- As previous we will leverage the random sampling, but now we will apply a median early termination policy.\n",
    "- The median stopping policy is based on the average of the primary metric reported for trials.  \n",
    "- Random sampling supports leveraging continuous and discrete hyperparameters.  If the primary metric is worse than the median, the job stops.\n",
    "\n",
    "- Hyperparameters are selected randomly from the defined search space.  \n",
    "- Note below we define the following hyperparameters:\n",
    "    - **penalty_term** to be either 'l1' or 'l2'\n",
    "    - **C** which is a value from 0.01-10.0\n",
    "    - **max_iter** is a choice of either 10, 100, 150 or 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy, BanditPolicy, TruncationSelectionPolicy\n",
    "\n",
    "\n",
    "rndsamplemedian_command = command(\n",
    "    code=\"./hyperparametertune\",  # local path where the code is stored\n",
    "    command=\"python main.py --titanic ${{inputs.titanic}} --randomstate ${{inputs.randomstate}}\",\n",
    "    inputs={\n",
    "        \"titanic\": Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"azureml:titanic_prepped:1\",\n",
    "        ),\n",
    "        \"randomstate\": 0,\n",
    "        \"penalty_term\": 'l1',\n",
    "        \"C\": 0.01,\n",
    "        \"max_iter\": 100,\n",
    "    },\n",
    "    environment=\"job_base_env@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    display_name=\"RandomSamplingwMedianPolicy\",\n",
    ")\n",
    "\n",
    "# #Set Parameter expressions\n",
    "# #choice, randint, qlognormal, qnormal, qloguniform, quniform, lognormal, normal, loguniform, uniform\n",
    "rnd_sample_median_job_for_sweep = rndsamplemedian_command(\n",
    "    penalty_term=Choice(values=['l2', 'l1']),\n",
    "    C=Uniform(min_value=0.01, max_value=10.0),\n",
    "    max_iter=Choice(values=[10, 100, 150, 200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "sweep_job = rnd_sample_median_job_for_sweep.sweep(\n",
    "    compute=\"cpu-cluster\",\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"training_roc_auc_score\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "sweep_job.set_limits(max_total_trials=120, \n",
    "                     max_concurrent_trials=10, \n",
    "                     timeout=7200)\n",
    "\n",
    "#early_termination - Early termination policy to end poorly performing runs. If no termination policy is specified, all configurations are run to completion. \n",
    "sweep_job.early_termination = MedianStoppingPolicy(evaluation_interval= 1, delay_evaluation= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_sweep_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = returned_sweep_job.name\n",
    "print('run_id:' + run_id)\n",
    "experiment = returned_job.experiment_name\n",
    "print(\"experiment:\" + experiment)\n",
    "\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_job_status(experiment_id, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling with Bandit Policy\n",
    "\n",
    "- As previous we will leverage the random sampling, but now we will apply a bandit early termination policy which will leverage the `slack_factor` to determine if a trial should be ended.\n",
    "- Random sampling supports leveraging continuous and discrete hyperparameters.  If the primary metric is worse than the median, the job stops.\n",
    "\n",
    "- Hyperparameters are selected randomly from the defined search space.  \n",
    "- Note below we define the following hyperparameters:\n",
    "    - **penalty_term** to be either 'l1' or 'l2'\n",
    "    - **C** which is a value from 0.01-10.0\n",
    "    - **max_iter** is a choice of either 10, 100, 150 or 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy, BanditPolicy, TruncationSelectionPolicy\n",
    "\n",
    "\n",
    "my_job = command(\n",
    "    code=\"./hyperparametertune\",  # local path where the code is stored\n",
    "    command=\"python main.py --titanic ${{inputs.titanic}} --randomstate ${{inputs.randomstate}}\",\n",
    "    inputs={\n",
    "        \"titanic\": Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"azureml:titanic_prepped:1\",\n",
    "        ),\n",
    "        \"randomstate\": 0,\n",
    "        \"penalty_term\": 'l1',\n",
    "        \"C\": 0.01,\n",
    "        \"max_iter\": 100,\n",
    "    },\n",
    "    environment=\"job_base_env@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    display_name=\"RandomSamplingwBanditPolicy\",\n",
    ")\n",
    "\n",
    "# #Set Parameter expressions\n",
    "# #choice, randint, qlognormal, qnormal, qloguniform, quniform, lognormal, normal, loguniform, uniform\n",
    "command_job_for_sweep = my_job(\n",
    "    penalty_term=Choice(values=['l2', 'l1']),\n",
    "    C=Uniform(min_value=0.01, max_value=10.0),\n",
    "    max_iter=Choice(values=[10, 100, 150, 200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"cpu-cluster\",\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"training_roc_auc_score\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "sweep_job.set_limits(max_total_trials=60, \n",
    "                     max_concurrent_trials=10, \n",
    "                     timeout=7200)\n",
    "\n",
    "#early_termination - Early termination policy to end poorly performing runs. If no termination policy is specified, all configurations are run to completion. \n",
    "sweep_job.early_termination = BanditPolicy(slack_factor = 0.1, delay_evaluation = 5, evaluation_interval = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_sweep_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = returned_sweep_job.name\n",
    "print('run_id:' + run_id)\n",
    "experiment = returned_job.experiment_name\n",
    "print(\"experiment:\" + experiment)\n",
    "\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)\n",
    "\n",
    "#get status\n",
    "get_job_status(experiment_id, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Sampling\n",
    "\n",
    "- Bayesian sampling leverages how a previous trial did in regard to the primary meteric to determine what to pick for hyperparameter.\n",
    "- It is recommended to havea  max number of jobs >= 20x  the number of hyperparameters being tuned.\n",
    "\n",
    "- Baysesian sampling supports: `choice`, `quniform` and `uniform` hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy, BanditPolicy, TruncationSelectionPolicy\n",
    "\n",
    "\n",
    "my_job = command(\n",
    "    code=\"./hyperparametertune\",  # local path where the code is stored\n",
    "    command=\"python main.py --titanic ${{inputs.titanic}} --randomstate ${{inputs.randomstate}}\",\n",
    "    inputs={\n",
    "        \"titanic\": Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"azureml:titanic_prepped:1\",\n",
    "        ),\n",
    "        \"randomstate\": 0,\n",
    "        \"penalty_term\": 'l1',\n",
    "        \"C\": 0.01,\n",
    "        \"max_iter\": 100,\n",
    "    },\n",
    "    environment=\"job_base_env@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    display_name=\"Bayesian\",\n",
    ")\n",
    "\n",
    "# #Set Parameter expressions\n",
    "command_job_for_sweep = my_job(\n",
    "    penalty_term=Choice(values=['l2', 'l1']),\n",
    "    C=Uniform(min_value=0.01, max_value=10.0),\n",
    "    max_iter=Choice(values=[10, 100, 150, 200]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"cpu-cluster\",\n",
    "    sampling_algorithm=\"bayesian\",\n",
    "    primary_metric=\"test_AUC\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "# define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=60, max_concurrent_trials=10, timeout=7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "# get a URL for the status of the job\n",
    "returned_sweep_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_sweep_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = returned_sweep_job.name\n",
    "print('run_id:' + run_id)\n",
    "experiment = returned_job.experiment_name\n",
    "print(\"experiment:\" + experiment)\n",
    "\n",
    "current_experiment=dict(mlflow.get_experiment_by_name(experiment))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "print(experiment_id)\n",
    "\n",
    "#get status\n",
    "get_job_status(experiment_id, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_run_results(experiment_id, run_id):\n",
    "    df = mlflow.search_runs([experiment_id])\n",
    "    rslt_df = df[(df['tags.mlflow.parentRunId'] == run_id )]\n",
    "    rslt_df_finished = rslt_df[rslt_df['status'] == 'FINISHED']\n",
    "\n",
    "    while rslt_df.shape[0] == 0:\n",
    "        print('waiting for jobs to register')\n",
    "        df = mlflow.search_runs([experiment_id])\n",
    "        rslt_df = df[(df['tags.mlflow.parentRunId'] == run_id )]\n",
    "        rslt_df_finished = rslt_df[rslt_df['status'] == 'FINISHED']\n",
    "        time.sleep(5)\n",
    "\n",
    "    while rslt_df_finished.shape[0] != rslt_df.shape[0]:\n",
    "        df = mlflow.search_runs([experiment_id])\n",
    "        rslt_df = df[(df['tags.mlflow.parentRunId'] == run_id )]\n",
    "        rslt_df_finished = rslt_df[rslt_df['status'] == 'FINISHED']\n",
    "        status = rslt_df[\"status\"].unique()\n",
    "        print(status)\n",
    "        for x in status:\n",
    "            rslt_df_status = rslt_df[rslt_df['status'] == x]\n",
    "            print(returned_sweep_job.display_name + ', Number:' + str(x) + \" \" +  str(rslt_df_status.shape[0]))\n",
    "        time.sleep(5)\n",
    "\n",
    "    rslt_df_status = rslt_df[rslt_df['status'] == 'FINISHED']\n",
    "    return rslt_df_status\n",
    "\n",
    "df = get_job_run_results(experiment_id, run_id) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='metrics.test_AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_id = df.iat[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = mlflow.sklearn.load_model(f\"runs:/{best_run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = os.path.join(os.getcwd(), \"titanic_prepped_mltable\")\n",
    "print(script_folder)\n",
    "tbl = mltable.load(uri=script_folder)\n",
    "df  = tbl.to_pandas_dataframe()\n",
    "columns_to_keep =  ['Embarked', 'Loc', 'Sex','Pclass', 'Age', 'Fare', 'GroupSize']\n",
    "X_raw           = df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipeline_model.predict(X_raw)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "job_env",
   "language": "python",
   "name": "job_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
